<!DOCTYPE html>
<!--********************************************-->
<!--*       Generated from PreTeXt source      *-->
<!--*                                          *-->
<!--*         https://pretextbook.org          *-->
<!--*                                          *-->
<!--********************************************-->
<html lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>NetSci Random Walks</title>
<meta name="Keywords" content="Authored in PreTeXt">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<script>window.MathJax = {
  tex: {
    inlineMath: [['\\(','\\)']],
    tags: "none",
    useLabelIds: true,
    tagSide: "right",
    tagIndent: ".8em",
    packages: {'[+]': ['base', 'extpfeil', 'ams', 'amscd', 'newcommand', 'knowl']}
  },
  options: {
    ignoreHtmlClass: "tex2jax_ignore",
    processHtmlClass: "has_am",
  },
  chtml: {
    scale: 0.88,
    mtextInheritFont: true
  },
  loader: {
    load: ['input/asciimath', '[tex]/extpfeil', '[tex]/amscd', '[tex]/newcommand', '[pretext]/mathjaxknowl3.js'],
    paths: {pretext: "https://pretextbook.org/js/lib"},
  },
};
</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script><script xmlns:svg="http://www.w3.org/2000/svg" src="https://pretextbook.org/js/lib/jquery.min.js"></script><script xmlns:svg="http://www.w3.org/2000/svg" src="https://pretextbook.org/js/lib/jquery.sticky.js"></script><script xmlns:svg="http://www.w3.org/2000/svg" src="https://pretextbook.org/js/lib/jquery.espy.min.js"></script><script xmlns:svg="http://www.w3.org/2000/svg" src="https://pretextbook.org/js/0.13/pretext.js"></script><script xmlns:svg="http://www.w3.org/2000/svg" src="https://pretextbook.org/js/0.13/pretext_add_on.js"></script><script xmlns:svg="http://www.w3.org/2000/svg" src="https://pretextbook.org/js/lib/knowl.js"></script><!--knowl.js code controls Sage Cells within knowls--><script xmlns:svg="http://www.w3.org/2000/svg">sagecellEvalName='Evaluate (Sage)';
</script><link xmlns:svg="http://www.w3.org/2000/svg" href="https://fonts.googleapis.com/css?family=Open+Sans:400,400italic,600,600italic" rel="stylesheet" type="text/css">
<link xmlns:svg="http://www.w3.org/2000/svg" href="https://fonts.googleapis.com/css?family=Inconsolata:400,700&amp;subset=latin,latin-ext" rel="stylesheet" type="text/css">
<link xmlns:svg="http://www.w3.org/2000/svg" href="https://pretextbook.org/css/0.31/pretext.css" rel="stylesheet" type="text/css">
<link xmlns:svg="http://www.w3.org/2000/svg" href="https://pretextbook.org/css/0.31/pretext_add_on.css" rel="stylesheet" type="text/css">
<link xmlns:svg="http://www.w3.org/2000/svg" href="https://pretextbook.org/css/0.31/banner_default.css" rel="stylesheet" type="text/css">
<link xmlns:svg="http://www.w3.org/2000/svg" href="https://pretextbook.org/css/0.31/toc_default.css" rel="stylesheet" type="text/css">
<link xmlns:svg="http://www.w3.org/2000/svg" href="https://pretextbook.org/css/0.31/knowls_default.css" rel="stylesheet" type="text/css">
<link xmlns:svg="http://www.w3.org/2000/svg" href="https://pretextbook.org/css/0.31/style_default.css" rel="stylesheet" type="text/css">
<link xmlns:svg="http://www.w3.org/2000/svg" href="https://pretextbook.org/css/0.31/colors_default.css" rel="stylesheet" type="text/css">
<link xmlns:svg="http://www.w3.org/2000/svg" href="https://pretextbook.org/css/0.31/setcolors.css" rel="stylesheet" type="text/css">
<!-- 2019-10-12: Temporary - CSS file for experiments with styling --><link xmlns:svg="http://www.w3.org/2000/svg" href="developer.css" rel="stylesheet" type="text/css">
</head>
<body class="pretext-book has-toc has-sidebar-left">
<a class="assistive" href="#content">Skip to main content</a><div xmlns:svg="http://www.w3.org/2000/svg" id="latex-macros" class="hidden-content" style="display:none">\(\newcommand{\identity}{\mathrm{id}}
\newcommand{\notdivide}{{\not{\mid}}}
\newcommand{\notsubset}{\not\subset}
\newcommand{\lcm}{\operatorname{lcm}}
\newcommand{\gf}{\operatorname{GF}}
\newcommand{\inn}{\operatorname{Inn}}
\newcommand{\aut}{\operatorname{Aut}}
\newcommand{\Hom}{\operatorname{Hom}}
\newcommand{\cis}{\operatorname{cis}}
\newcommand{\chr}{\operatorname{char}}
\newcommand{\Null}{\operatorname{Null}}


\def\Z{\mathbb Z}
\def\R{\mathbb R}
\def\Q{\mathbb Q}
\def\N{{\mathbb N}}
\def\C{\mathbb C}

\def\ba{{\mathbf{a}}}
\def\bb{\mathbf{b}}
\def\bh{{\mathbf{h}}}
\def\bu{{\mathbf{u}}}
\def\bv{{\mathbf{v}}}
\def\bw{{\mathbf{w}}}   
\def\bx{{\mathbf{x}}}
\def\by{\mathbf{y}}    
\def\bone{{\mathbf{1}}}
\def\bzero{\mathbf{0}}

\def\var{{\mbox{var}}}
\def\P{{\mathbb{P}}}
\def\E{{\mathbb{E}}}


\def\cA{{\overline{A}}}

\def\kin{k^{\mathrm{in}}}
\def\kout{k^{\mathrm{out}}}

\newcommand{\indeg}[1]{k^{\mathrm{in}}_{#1}}
\newcommand{\outdeg}[1]{k^{\mathrm{out}}_{#1}}

\tikzset{-&gt;-/.style={decoration={
 markings,
 mark=at position .5 with {\arrow{latex}}},postaction={decorate}}}
\newcommand{\lt}{&lt;}
\newcommand{\gt}{&gt;}
\newcommand{\amp}{&amp;}
\)</div>
<header id="masthead" class="smallbuttons"><div class="banner"><div class="container">
<a id="logo-link" href=""></a><div class="title-container">
<h1 class="heading"><a href="netsci.html"><span class="title">Network Science:</span> <span class="subtitle">Activities and Exercises</span></a></h1>
<p class="byline">Andrew Beveridge</p>
</div>
</div></div>
<nav xmlns:svg="http://www.w3.org/2000/svg" id="primary-navbar" class="navbar"><div class="container">
<div class="navbar-top-buttons">
<button class="sidebar-left-toggle-button button active" aria-label="Show or hide table of contents sidebar">Contents</button><div class="tree-nav toolbar toolbar-divisor-3"><span class="threebuttons"><a id="previousbutton" class="previous-button toolbar-item button" href="graphs.html" title="Previous">Prev</a><a id="upbutton" class="up-button button toolbar-item" href="ch-community.html" title="Up">Up</a><a id="nextbutton" class="next-button button toolbar-item" href="modularity.html" title="Next">Next</a></span></div>
</div>
<div class="navbar-bottom-buttons toolbar toolbar-divisor-4">
<button class="sidebar-left-toggle-button button toolbar-item active">Contents</button><a class="previous-button toolbar-item button" href="graphs.html" title="Previous">Prev</a><a class="up-button button toolbar-item" href="ch-community.html" title="Up">Up</a><a class="next-button button toolbar-item" href="modularity.html" title="Next">Next</a>
</div>
</div></nav></header><div class="page">
<div xmlns:svg="http://www.w3.org/2000/svg" id="sidebar-left" class="sidebar" role="navigation"><div class="sidebar-content">
<nav id="toc"><ul>
<li class="link frontmatter"><a href="frontmatter.html" data-scroll="frontmatter"><span class="title">Front Matter</span></a></li>
<li class="link part"><a href="part-networks.html" data-scroll="part-networks"><span class="codenumber">I</span> <span class="title">Analyzing Networks</span></a></li>
<li class="link">
<a href="ch-community.html" data-scroll="ch-community"><span class="codenumber">1</span> <span class="title">Networks and Communities</span></a><ul>
<li><a href="graphs.html" data-scroll="graphs">Graphs and Digraphs</a></li>
<li><a href="randomwalk.html" data-scroll="randomwalk" class="active">Random Walks</a></li>
<li><a href="modularity.html" data-scroll="modularity">Modularity</a></li>
<li><a href="communities.html" data-scroll="communities">Community Detection in Gephi</a></li>
</ul>
</li>
<li class="link">
<a href="ch-power-law.html" data-scroll="ch-power-law"><span class="codenumber">2</span> <span class="title">Power Laws</span></a><ul>
<li><a href="randvar.html" data-scroll="randvar">Discrete Random Variables</a></li>
<li><a href="probdist.html" data-scroll="probdist">Probability Distributions</a></li>
<li><a href="powerlaw.html" data-scroll="powerlaw">Power Laws</a></li>
</ul>
</li>
<li class="link">
<a href="ch-centrality.html" data-scroll="ch-centrality"><span class="codenumber">3</span> <span class="title">Centralities</span></a><ul>
<li><a href="centrality.html" data-scroll="centrality">Centrality Measures</a></li>
<li><a href="algcentrality.html" data-scroll="algcentrality">Algebraic Centrality</a></li>
<li><a href="hits.html" data-scroll="hits">Hubs and Authorities</a></li>
<li><a href="us-airline.html" data-scroll="us-airline">Analyzing the US Airline Network</a></li>
</ul>
</li>
<li class="link part"><a href="part-models.html" data-scroll="part-models"><span class="codenumber">II</span> <span class="title">Modeling Networks</span></a></li>
<li class="link">
<a href="ch-models.html" data-scroll="ch-models"><span class="codenumber">4</span> <span class="title">Random Models for Networks</span></a><ul>
<li><a href="randomgraph.html" data-scroll="randomgraph">Erdos-Renyi Random Graph</a></li>
<li><a href="giantcomp.html" data-scroll="giantcomp">The Emergence of the Giant Component</a></li>
<li><a href="branching.html" data-scroll="branching">The Branching Process</a></li>
<li><a href="pricemodel.html" data-scroll="pricemodel">Price's Model for a Citation Network</a></li>
<li><a href="smallworld.html" data-scroll="smallworld">The Small World Model</a></li>
<li><a href="navsmallworld.html" data-scroll="navsmallworld">Navigable Small World Model</a></li>
</ul>
</li>
<li class="link">
<a href="ch-processes.html" data-scroll="ch-processes"><span class="codenumber">5</span> <span class="title">Processes on Networks</span></a><ul>
<li><a href="cascades.html" data-scroll="cascades">Network Cascades</a></li>
<li><a href="epidemics.html" data-scroll="epidemics">Epidemics on Networks</a></li>
</ul>
</li>
</ul></nav><div class="extras"><nav><a class="pretext-link" href="https://pretextbook.org">Authored in PreTeXt</a><a href="https://www.mathjax.org"><img title="Powered by MathJax" src="https://www.mathjax.org/badge/badge.gif" alt="Powered by MathJax"></a></nav></div>
</div></div>
<main class="main"><div id="content" class="pretext-content"><section xmlns:svg="http://www.w3.org/2000/svg" class="section" id="randomwalk"><h2 class="heading hide-type">
<span class="type">Section</span> <span class="codenumber">1.2</span> <span class="title">Random Walks</span>
</h2>
<section class="introduction" id="introduction-2"><p id="p-39">A <em class="emphasis">random walk</em> starting at vertex \(v_0\) proceeds as follows: at each time \(t \geq 1\text{,}\) pick a random out-neighbor of \(v_{t-1}\) and walk to it. If vertex \(v_{t-1}\) has no out-neighbors, then we stay where we are.</p>
<p id="p-40">A nice way to "stay where we are" is to add a loop to each vertex with no out-neighbors. So when \(k_i^{\mathrm{out}} = 0\text{,}\) we update the adjacency matrix so that \(a_{ii}=1\text{.}\) So we will assume that this is the case.</p>
<p id="p-41">At each step, \(v_t\) is chosen uniformly from the out-neighbors of \(v_{t-1}\text{.}\) Using conditional probability notation, we have</p>
<div class="displaymath">
\begin{equation*}
P_{ij} = \Pr (v_t=j \mid v_{t-1} = i ) =
\left\{
\begin{array}{cc}
\displaystyle{\frac{1}{k_i^{\mathrm{out}}}} &amp; \mbox{if } ij \in E, \\
0 &amp; \mbox{otherwise}.
\end{array}
\right.
\end{equation*}
</div>
<p class="continuation">The <em class="emphasis">transition matrix</em> \(P = ( P_{ij})\) collects the transition probabilities. The \(i\)th row contains all the transition probabilities starting at vertex \(i\text{.}\) Finally, we can write our transition matrix as</p>
<div class="displaymath">
\begin{equation*}
P = D^{-1} A
\end{equation*}
</div>
<p class="continuation">where \(D\)  is the diagonal matrix with  \(D_{ii} = \max \left\{ k_i^{\mathrm{out}}, 1 \right\}\) and  \(A\) is the adjacency matrix.</p></section><section class="exercises" id="exercises-2"><h3 class="heading hide-type">
<span class="type">Exercises</span> <span class="codenumber"></span> <span class="title">Practice Problems</span>
</h3>
<article class="exercise exercise-like" id="exercise-8"><h6 class="heading">
<span class="codenumber">1<span class="period">.</span></span><span class="space"> </span><span class="title">Random Walk on an Undirected Graph.</span>
</h6>
<ol id="p-42" class="lower-alpha">
<li id="li-20">
<p id="p-43">Find the transition matrix \(P\)  of the following undirected graph. Hint: construct \(P\)   row by row. And remember that when \(k_i^{\mathrm{out}}=0\text{,}\) we set \(a_{ii}=1\text{,}\) corresponding to the move "stay where we are." <div class="image-box" style="width: 30%; margin-left: 35%; margin-right: 35%;"><img src="./images/undirected-graph.png" class="contained"></div></p>
<p id="p-44"><a data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-8" id="solution-8"><span class="type">Solution.</span> </a><div class="hidden-content tex2jax_ignore" id="hk-solution-8"><div class="solution solution-like"><div class="displaymath" id="p-45">
\begin{equation*}
P =
\begin{bmatrix}
0 &amp; 1/2 &amp; 0 &amp; 0 &amp; 1/2 &amp; 0  \\
1/3 &amp; 0 &amp; 1/3 &amp; 0 &amp; 1/3 &amp; 0  \\
0 &amp; 1/2 &amp; 0 &amp; 1/2 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 1/3 &amp; 0 &amp; 1/3 &amp; 1/3  \\
1/3 &amp; 1/3 &amp; 0 &amp; 1/3 &amp; 0 &amp; 0  \\
0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0  \\
\end{bmatrix}
\end{equation*}
</div></div></div></p>
</li>
<li id="li-21">
<p id="p-46">Show that the all-ones vector \(\bone\) is a right eigenvector for  eigenvalue \(\lambda=1\text{.}\) In other words, confirm that</p>
<div class="displaymath">
\begin{equation*}
P \bone = \bone.
\end{equation*}
</div>
<p class="continuation">What is the meaning of this equation? <a data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-9" id="solution-9"><span class="type">Solution.</span> </a><div class="hidden-content tex2jax_ignore" id="hk-solution-9"><div class="solution solution-like"><p id="p-47">Right multiplication by \(\bone\) sums all the exit probabilities from each vertex. So of course, these numbers sum to 1.</p></div></div></p>
</li>
</ol></article><article class="exercise exercise-like" id="exercise-9"><h6 class="heading">
<span class="codenumber">2<span class="period">.</span></span><span class="space"> </span><span class="title">Long Term Behavior of a Random Walk of an Undirected Graph.</span>
</h6>
<p id="p-48">Consider the undirected graph from Problem 1. In your mind, repeatedly simulate a random walk starting from vertex 1. Follow this walk for about 15 steps or so. Where are you most likely to end up? Least likely? How do your observations relate to:  the distance of the vertex from vertex 1? the degree of the  vertex?</p>
<p id="p-49"><a data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-10" id="solution-10"><span class="type">Solution.</span> </a><div class="hidden-content tex2jax_ignore" id="hk-solution-10"><div class="solution solution-like"><p id="p-50">It is possible to end at any vertex. Vertex 6 is definitely visited the least at the end of the walk. Vertices with degree 3 seem to be the candidates for lots of visits at the end. But it is not clear how to compare these vertices with each other.</p></div></div></p></article><article class="exercise exercise-like" id="exercise-10"><h6 class="heading">
<span class="codenumber">3<span class="period">.</span></span><span class="space"> </span><span class="title">Powers of the Transition Matrix.</span>
</h6>
<ol id="p-51" class="lower-alpha">
<li id="li-22">
<p id="p-52">Here is the matrix \(P^2\) for the undirected graph in Problem 1.</p>
<div class="displaymath">
\begin{equation*}
P^2 =
\begin{bmatrix}
\frac{1}{3} &amp; \frac{1}{6} &amp; \frac{1}{6} &amp; \frac{1}{6} &amp; \frac{1}{6} &amp; 0 \\[6pt]
\frac{1}{9} &amp; \frac{4}{9} &amp; 0 &amp; \frac{5}{18} &amp; \frac{1}{6} &amp; 0 \\[6pt]
\frac{1}{6} &amp; 0 &amp; \frac{1}{3} &amp; 0 &amp; \frac{1}{3} &amp; \frac{1}{6} \\[6pt]
\frac{1}{9} &amp; \frac{5}{18} &amp; 0 &amp; \frac{11}{18} &amp; 0 &amp; 0 \\[6pt]
\frac{1}{9} &amp; \frac{1}{6} &amp; \frac{2}{9} &amp; 0 &amp; \frac{7}{18} &amp; \frac{1}{9} \\[6pt]
0 &amp; 0 &amp; \frac{1}{3} &amp; 0 &amp; \frac{1}{3} &amp; \frac{1}{3}
\end{bmatrix}
\end{equation*}
</div>
<p class="continuation">What does row \(i\) tell you about the instruction "take two random steps from vertex \(i\text{?}\)" <a data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-11" id="solution-11"><span class="type">Solution.</span> </a><div class="hidden-content tex2jax_ignore" id="hk-solution-11"><div class="solution solution-like"><p id="p-53">The \((i,j)\) entry of \(P^2\) tells you the probability of a random walk starting at \(i\) ending at \(j\) after 2 steps.</p></div></div></p>
</li>
<li id="li-23"><p id="p-54">Using part (a) as a guide, give an interpretation for row \(i\) of the matrix \(P^3\text{.}\) <a data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-12" id="solution-12"><span class="type">Solution.</span> </a><div class="hidden-content tex2jax_ignore" id="hk-solution-12"><div class="solution solution-like"><p id="p-55">The \((i,j)\) entry of \(P^3\) tells you the probability of a random walk starting at \(i\) ending at \(j\) after 3 steps.</p></div></div></p></li>
<li id="li-24"><p id="p-56">What do the rows of matrix \(P^t\) describe? <a data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-13" id="solution-13"><span class="type">Solution.</span> </a><div class="hidden-content tex2jax_ignore" id="hk-solution-13"><div class="solution solution-like"><p id="p-57">The \((i,j)\) entry of \(P^t\) tells you the probability of a random walk starting at \(i\) ending at \(j\) after \(t\) steps.</p></div></div></p></li>
<li id="li-25">
<p id="p-58">For \(1 \leq i \leq 6\text{,}\) let \(\mathbf{e}_i\) denote the " elementary vector" whose \(j\)-th entry is</p>
<div class="displaymath">
\begin{equation*}
\mathbf{e}_i(j) = \left\{
\begin{array}{cl}
1 &amp; i=j \\
0 &amp; \mbox{otherwise.}
\end{array}
\right.
\end{equation*}
</div>
<p class="continuation">In other words,</p>
<div class="displaymath">
\begin{align*}
\mathbf{e}_1&amp;= \begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \end{bmatrix}\\
\mathbf{e}_2&amp;= \begin{bmatrix} 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \end{bmatrix}\\
\mathbf{e}_3&amp;= \begin{bmatrix} 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 \end{bmatrix}\\
\mathbf{e}_4&amp;= \begin{bmatrix} 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 \end{bmatrix}\\
\mathbf{e}_5&amp;= \begin{bmatrix} 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \end{bmatrix}
\end{align*}
</div>
<p id="p-59">What does the vector</p>
<div class="displaymath">
\begin{equation*}
\mathbf{e}_i \, P^t
\end{equation*}
</div>
<p class="continuation">describe? <a data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-14" id="solution-14"><span class="type">Solution.</span> </a><div class="hidden-content tex2jax_ignore" id="hk-solution-14"><div class="solution solution-like"><p id="p-60">The  row vector \(\mathbf{e}_i \, P^t\) is row \(i\) of matrix \(P^t\text{.}\) As described in the previous part, the \(j\)th entry of this vector is the probability that you are at vertex \(j\) after taking \(t\) random steps from \(i\text{.}\)</p></div></div></p>
</li>
</ol></article><article class="exercise exercise-like" id="exercise-11"><h6 class="heading">
<span class="codenumber">4<span class="period">.</span></span><span class="space"> </span><span class="title">A Left Eigenvector for an Undirected Graph.</span>
</h6>
<p id="p-61">Let \(P\) be the transition matrix for the graph in Problem 1. Consider the row vector</p>
<div class="displaymath">
\begin{equation*}
\bv =
\begin{bmatrix}
v_1 &amp; v_2 &amp; v_3 &amp; v_4 &amp; v_5 &amp; v_6
\end{bmatrix}
=
\begin{bmatrix}
2 &amp; 3 &amp; 2 &amp; 3 &amp; 3 &amp; 1
\end{bmatrix}
\end{equation*}
</div>
<ol class="lower-alpha">
<li id="li-26">
<p id="p-62">Check that the row vector \(\bv\) satisfies</p>
<div class="displaymath">
\begin{equation*}
\bv  \,P = \bv.
\end{equation*}
</div>
<p class="continuation">We have a name for this equation: say that "\(\bv\) is a <em class="emphasis">left</em> eigenvector of the transition matrix \(P\) for eigenvalue \(\lambda=1\text{.}\)" (In other words, the eigenvectors that you are used to are actually <em class="emphasis">right</em> eigenvectors.) <a data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-15" id="solution-15"><span class="type">Solution.</span> </a><div class="hidden-content tex2jax_ignore" id="hk-solution-15"><div class="solution solution-like">
<p id="p-63">We have</p>
<div class="displaymath">
\begin{align*}
&amp; \begin{bmatrix}
2 &amp; 3 &amp; 2 &amp; 3 &amp; 3 &amp; 1
\end{bmatrix}
\begin{bmatrix}
0 &amp; 1/2 &amp; 0 &amp; 0 &amp; 1/2 &amp; 0\\
1/3 &amp; 0 &amp; 1/3 &amp; 0 &amp; 1/3 &amp; 0\\
0 &amp; 1/2 &amp; 0 &amp; 1/2 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 1/3 &amp; 0 &amp; 1/3 &amp; 1/3\\
1/3 &amp; 1/3 &amp; 0 &amp; 1/3 &amp; 0 &amp; 0\\
0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0\\
\end{bmatrix}\\
&amp;=
\begin{bmatrix}
2 &amp; 3 &amp; 2 &amp; 3 &amp; 3 &amp; 1
\end{bmatrix}
\end{align*}
</div>
<p id="p-64"></p>
</div></div></p>
</li>
<li id="li-27"><p id="p-65">Relate the entries of \(\bv\) to the degrees of the graph. <a data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-16" id="solution-16"><span class="type">Solution.</span> </a><div class="hidden-content tex2jax_ignore" id="hk-solution-16"><div class="solution solution-like"><p id="p-66">The entries are the degrees of the vertices.</p></div></div></p></li>
</ol></article><article class="exercise exercise-like" id="exercise-12"><h6 class="heading">
<span class="codenumber">5<span class="period">.</span></span><span class="space"> </span><span class="title">Stationary Distribution for an Undirected Graph.</span>
</h6>
<p id="p-67">A vector whose entries are nonnegative and sum to one correspond to a <em class="emphasis">probability distribution</em> on the vertices of \(G\text{.}\) A distribution \(\pi\) is  <em class="emphasis">stationary</em> for \(P\) when</p>
<div class="displaymath">
\begin{equation*}
\pi P = \pi.
\end{equation*}
</div>
<p class="continuation">The amazing Perron-Frobenius Theorem (a very general theorem) can be applied to the transition matrix \(P\) for a connected, non-bipartite undirected graph.</p>
<p id="p-68">In particular, it applies to the matrix \(P\) from the previous problems. And it tells us more information about the left eigenvector  \(\bv\text{.}\) Two of the properties that it tells us are:</p>
<ul class="disc">
<li id="li-28"><p id="p-69">All of the other eigenvalues satisify \(| \lambda_i| &lt; 1\text{.}\) In other words, \(\bv\) is the <em class="emphasis">dominant eigenvector</em> of \(P\text{.}\)</p></li>
<li id="li-29">
<p id="p-70">Assuming that we have scaled the row vector \(\bv\) so that its entries sum to 1, we have</p>
<div class="displaymath">
\begin{align*}
\lim_{t \rightarrow \infty} P^t  \, = \, \bone \,  \bv
&amp;=
\begin{bmatrix}
v_1 &amp; v_2 &amp; v_3 &amp; v_4 &amp; v_5 &amp; v_6\\
v_1 &amp; v_2 &amp; v_3 &amp; v_4 &amp; v_5 &amp; v_6\\
v_1 &amp; v_2 &amp; v_3 &amp; v_4 &amp; v_5 &amp; v_6\\
v_1 &amp; v_2 &amp; v_3 &amp; v_4 &amp; v_5 &amp; v_6\\
v_1 &amp; v_2 &amp; v_3 &amp; v_4 &amp; v_5 &amp; v_6\\
v_1 &amp; v_2 &amp; v_3 &amp; v_4 &amp; v_5 &amp; v_6\\
\end{bmatrix}
\end{align*}
</div>
<p id="p-71">where</p>
<div class="displaymath">
\begin{equation*}
\bv =
\begin{bmatrix}
v_1 &amp; v_2 &amp; v_3 &amp; v_4 &amp; v_5 &amp; v_6
\end{bmatrix}
=
\begin{bmatrix}
\frac{2}{14} &amp; \frac{3}{14} &amp; \frac{2}{14} &amp; \frac{3}{14} &amp; \frac{3}{14} &amp; \frac{1}{14}
\end{bmatrix}.
\end{equation*}
</div>
</li>
</ul>
<p class="continuation">Given this information:</p>
<ol class="lower-alpha">
<li id="li-30"><p id="p-72">What new properties do we now know about the vector (and probability distributrion) \(\bv\text{?}\) <a data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-17" id="solution-17"><span class="type">Solution.</span> </a><div class="hidden-content tex2jax_ignore" id="hk-solution-17"><div class="solution solution-like"><p id="p-73">The row vector \(\bv\) is the dominant eigenvector and  every row of \(\lim_{t \rightarrow \infty} P^t\) converges to \(\pi\text{.}\)</p></div></div></p></li>
<li id="li-31"><p id="p-74">After taking many random steps, what is the probability that we are at vertex \(i\text{?}\) <a data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-18" id="solution-18"><span class="type">Solution.</span> </a><div class="hidden-content tex2jax_ignore" id="hk-solution-18"><div class="solution solution-like"><p id="p-75">Row \(i\) of \(P^t\) is the probability distribution for a random walk started at vertex \(i\text{.}\) So this distribution converges to \(\pi\text{.}\) In particular, as \(t \rightarrow \infty\text{,}\) the probability that we are at vertex \(j\) is \(k_j/14\text{.}\)</p></div></div></p></li>
</ol></article><article class="exercise exercise-like" id="exercise-13"><h6 class="heading">
<span class="codenumber">6<span class="period">.</span></span><span class="space"> </span><span class="title">Undirected Graphs: the General Case.</span>
</h6>
<p id="p-76">In the previous questions, you have focused on a particular undirected graph. Take a step back: these observations also hold in general!</p>
<p id="p-77">Let \(G\) be a connected, aperiodic, undirected graph with adjacency matrix \(A\) and transition matrix \(P = D^{-1}A\text{.}\)</p>
<ol class="lower-alpha">
<li id="li-32"><p id="p-78">Explain why \(P \bone = \bone\text{.}\) <a data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-19" id="solution-19"><span class="type">Solution.</span> </a><div class="hidden-content tex2jax_ignore" id="hk-solution-19"><div class="solution solution-like"><p id="p-79">Row \(i\) contains the probabilities of stepping from \(i\)  to a neighbor of vertex \(i\text{.}\) These probabiiities sum to 1.</p></div></div></p></li>
<li id="li-33">
<p id="p-80">Let \(\pi\) be the row vector</p>
<div class="displaymath">
\begin{equation*}
\pi =
\begin{bmatrix}
\frac{k_1}{2m} &amp; \frac{k_2}{2m} &amp;  \cdots &amp; \frac{k_n}{2m}
\end{bmatrix}
\end{equation*}
</div>
<p class="continuation">where \(n=|V|\) and \(m = |E|\) and \(k_i\) is the degree of vertex \(i\text{.}\) Explain why</p>
<div class="displaymath">
\begin{equation*}
\pi P = \pi.
\end{equation*}
</div>
<p class="continuation"><a data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-20" id="solution-20"><span class="type">Solution.</span> </a><div class="hidden-content tex2jax_ignore" id="hk-solution-20"><div class="solution solution-like">
<p id="p-81">The \(i\)th entry of \(\pi P\) is</p>
<div class="displaymath">
\begin{equation*}
\sum_{j=1}^n \frac{k_j}{2m} \frac{a_{ij}}{k_j} = \frac{1}{2m}  \sum_{j=1}^n a_{ij} = \frac{k_i}{2m}.
\end{equation*}
</div>
</div></div></p>
</li>
<li id="li-34"><p id="p-82">What is the meaning of the row vector \(\mathbf{e}_i \, P^t\text{,}\) where \(\mathbf{e}_i\) is the elementary vector from Problem 3(d)? <a data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-21" id="solution-21"><span class="type">Solution.</span> </a><div class="hidden-content tex2jax_ignore" id="hk-solution-21"><div class="solution solution-like"><p id="p-83">The row vector \(\mathbf{e}_i \, P^t \) is row \(i\) of \(P^t\text{.}\)</p></div></div></p></li>
<li id="li-35">
<p id="p-84">Explain why we have</p>
<div class="displaymath">
\begin{equation*}
\lim_{t \rightarrow \infty} \mathbf{e}_i \, P^t = \pi.
\end{equation*}
</div>
<p class="continuation">What does this equation mean for a random walk starting at vertex \(i\text{?}\) <a data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-22" id="solution-22"><span class="type">Solution.</span> </a><div class="hidden-content tex2jax_ignore" id="hk-solution-22"><div class="solution solution-like"><p id="p-85">Row \(i\) of \(P^t\) is the probability distribution for a random walk started at vertex \(i\text{.}\) This distribution converges to \(\pi\text{.}\) In particular, as \(t \rightarrow \infty\text{,}\) the probability that we are at vertex \(j\) is \(k_j/2m\text{.}\)</p></div></div></p>
</li>
</ol></article><article class="exercise exercise-like" id="exercise-14"><h6 class="heading">
<span class="codenumber">7<span class="period">.</span></span><span class="space"> </span><span class="title">Random Walk on a Directed Graph.</span>
</h6>
<p id="p-86">Things don't work out as nicely on directed graphs. We will work through an example to see some of the strange behaviors that can arise.</p>
<ol class="lower-alpha">
<li id="li-36"><p id="p-87">Find the transition matrix \(P\) of the following directed graph. Hint: construct \(P\) row by row. <div class="image-box" style="width: 30%; margin-left: 35%; margin-right: 35%;"><img src="./images/directed-graph.png" class="contained"></div> <a data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-23" id="solution-23"><span class="type">Solution.</span> </a><div class="hidden-content tex2jax_ignore" id="hk-solution-23"><div class="solution solution-like">
<p id="p-88">Since vertex 2 has no out-neighbors, we add a self-loop.</p>
<div class="displaymath">
\begin{equation*}
P =
\begin{bmatrix}
0 &amp; 1/2 &amp; 0 &amp; 0 &amp; 1/2 &amp; 0  \\
0 &amp; 1 &amp; 0&amp; 0 &amp; 0 &amp; 0  \\
1/2 &amp; 1/2 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0  \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1  \\
0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0  \\
\end{bmatrix}
\end{equation*}
</div>
</div></div></p></li>
<li id="li-37">
<p id="p-89">Confirm that</p>
<div class="displaymath">
\begin{equation*}
P \bone = \bone.
\end{equation*}
</div>
<p class="continuation">What is the meaning of this equation? <a data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-24" id="solution-24"><span class="type">Solution.</span> </a><div class="hidden-content tex2jax_ignore" id="hk-solution-24"><div class="solution solution-like"><p id="p-90">Right multiplication by \(\bone\) sums all the exit probabilities from each vertex. These numbers sum to 1, just as in the directed case. Note that adding the self-loop at vertex 2 is essential.</p></div></div></p>
</li>
</ol></article><article class="exercise exercise-like" id="exercise-15"><h6 class="heading">
<span class="codenumber">8<span class="period">.</span></span><span class="space"> </span><span class="title">Long Term Behavior of a Random Walk on Directed Graph.</span>
</h6>
<p id="p-91">Now simulate some random walks on the directed graph from Problem 7. This time, start your walk at vertex 1. You should see a couple of different kinds of behavior for this directed graph. Describe what you observe. <div class="image-box" style="width: 25%; margin-left: 37.5%; margin-right: 37.5%;"><img src="./images/directed-graph.png" class="contained"></div> <a data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-25" id="solution-25"><span class="type">Solution.</span> </a><div class="hidden-content tex2jax_ignore" id="hk-solution-25"><div class="solution solution-like"><p id="p-92">At the end of the walk, we must be at vertex 2, 5 or 6. If we step to vertex 2 then we remain there forever. On the other hand, if we step from vertex 1 to vertex 5 then we we can never get out of this two vertex "spider trap."</p></div></div></p></article><article class="exercise exercise-like" id="exercise-16"><h6 class="heading">
<span class="codenumber">9<span class="period">.</span></span><span class="space"> </span><span class="title">An Eigenvector for a Directed Graph.</span>
</h6>
<p id="p-93">Let's continue to explore the digraph in Problem 7.</p>
<ol class="lower-alpha">
<li id="li-38">
<p id="p-94">Check that the row vector</p>
<div class="displaymath">
\begin{equation*}
\begin{bmatrix}
0 &amp; 0 &amp; 0 &amp; 0 &amp; \frac{1}{2} &amp; \frac{1}{2}
\end{bmatrix}
\end{equation*}
</div>
<p class="continuation">satisfies</p>
<div class="displaymath">
\begin{equation*}
\bv \, P = \bv.
\end{equation*}
</div>
<p class="continuation">How does this relate to the behavior you saw in problem 4? What behavior doesn't this capture? <a data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-26" id="solution-26"><span class="type">Solution.</span> </a><div class="hidden-content tex2jax_ignore" id="hk-solution-26"><div class="solution solution-like">
<p id="p-95">One of the two long-term outcomes we observed was ending up in the "spider trap" and then alternate between vertices 5 and 6. So in the long run, we spend half our time at vertex 5 and half our time at vertex 6. However, even in this case, the vector <em class="emphasis">doesn't capture the periodic behavior</em> of our long-term random walk. If we first step to vertex 5 at time \(T\text{,}\) then we will also be at vertex 5 at time \(T+2, T+4, T+6, \) etc, and we will be at vertex 6 at time \(T+1, T+3, T+5, \) etc.</p>
<p id="p-96">Another behavior that we don't see in this vector is that we could have ended up at vertex 2, and then remained there forever. That doesn't even show up at all in this vector.</p>
</div></div></p>
</li>
<li id="li-39">
<p id="p-97">Find a different vector \(\bw \neq \bv\) such that</p>
<div class="displaymath">
\begin{equation*}
\bw \, P = \bw.
\end{equation*}
</div>
<p class="continuation"><a data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-27" id="solution-27"><span class="type">Solution.</span> </a><div class="hidden-content tex2jax_ignore" id="hk-solution-27"><div class="solution solution-like">
<p id="p-98">The vector</p>
<div class="displaymath">
\begin{equation*}
\bw =
\begin{bmatrix}
0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0
\end{bmatrix}
\end{equation*}
</div>
<p class="continuation">is a solution to  \(\bw \, P = \bw.\)</p>
</div></div></p>
</li>
<li id="li-40"><p id="p-99">Pick \(a,b \in \R\)  such that \(a+b=1\text{.}\) What can you say about the vector \(a \bv + b \bw\text{?}\) <a data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-28" id="solution-28"><span class="type">Solution.</span> </a><div class="hidden-content tex2jax_ignore" id="hk-solution-28"><div class="solution solution-like">
<p id="p-100">We have</p>
<div class="displaymath">
\begin{equation*}
(a \bv + b\bw) P = a (\bv P) + b (\bw) P = a \bv  + b \bw.
\end{equation*}
</div>
<p class="continuation">Indeed, they are both left eigenvectors for eigenvalue \(\lambda=1\text{.}\) So any linear combination is also a left eigenvector for eigenvalue \(\lambda=1\text{.}\)</p>
</div></div></p></li>
</ol>
<p class="continuation">As this problem shows, the eigenvectors for a weakly connected directed graph aren't enough to fully resolve the long-term behavior of random walks. This example has an infinite number of choices of \(a,b\) that produce distinct left eigenvectors. (In fact, the stationary distribution that we end up in depends upon the starting vertex.)</p></article></section></section></div></main>
</div>
</body>
</html>
