<?xml version="1.0" encoding="UTF-8" ?>





<chapter xml:id="randvar" xmlns:xi="http://www.w3.org/2001/XInclude">
	<title>Discrete Random Variables</title>
	<introduction>
		<p>

			</p><p>



</p>
</introduction>
<section xml:id="randvar0">
<title>Discrete Random Variables</title>
<p>

In an experiment <m>X</m>, we pick an element from our finite <em>sample space</em> <m>\Omega</m> and then make note of one of its numerical properties. For example, we could take <m>\Omega</m> to be the set of vertices in our graph, and let <m>X</m> be the degree of the chosen vertex.


			</p><p>


A <em>discrete random variable</em> <m>X: \Omega \rightarrow \R</m> is a real-valued function on the outcome of an experiment that can take finite or a countably infinite number of values. In other words, the image <m> T \subset \R</m> is a finite or countably infinite set. Most typically, our discrete random variables will only take on nonnegative integer values, so  <m>T = \Z_{\geq 0}</m> or <m>T = \{ 0, 1, 2, \ldots, M \}</m>.



			</p><p>
So at the end of it all, <m>X</m> is just a <em>function</em> from a set <m>\Omega</m> to <m>\R</m>. So what's with all the strange notation?
Let's start with the sample space <m>\Omega</m>. This is just a set. Why not call it <m>S</m>? We use <m>\Omega</m> as  a mnemonic for "outcome." Since we are running an experiment (multiple times), each trial produces an <em>outcome</em>. We then take a measurement of that outcome (represented by the random variable <m>X</m>).

			</p><p>

Now, the random variable <m>X</m> is actually a real-valued function <m>X: \Omega \rightarrow \R</m>.  So why use
<m>X</m> instead of <m>f</m>? Well, we are taking a measurement of an outcome of an experiment. In this context, we are more interested in the value of the measurement. The symbol  <m>X</m> encourages us to pay attention to the measurement (not the function) because it reminds us of the variable <m>x</m> from algebra.


</p>
<subsection xml:id="randvar1">
<title>Probability Mass Function</title>
<p>

A discrete random variable <m>X</m> has an associated <em>probability mass function (PMF)</em>
<me>
p_X(t) = \P [ X = t]
</me>
which gives the probability of each numerical value that the random variable can take. When <m>X</m> is clear from the context, we simply write <m>p(t) = \P [X=t]</m>.


		<example>
			<title>PMF for a Random Vertex Degree</title>
			<statement>
				<p>
Consider the experiment where we take <m>X</m> to be the degree of a vertex from the network shown below, chosen uniformly at random (meaning that every vertex is equally likely). Find the PMF for this experiment.




			<image width="60%" xml:id="fig-img-randvar0" source="images/graph7.png" />




<!--solution>
<p>
Here are the probabilities of picking a vertex of degree <m>0 \leq t \leq 6</m>:
<me>
\begin{array}{c|c|c|c|c|c|c}
\P(0) &amp; \P(1) &amp; \P(2) &amp; \P(3) &amp; \P(4) &amp; \P(5) &amp; \P(6) \\
\hline
\rule{0pt}{3.5ex} 0 &amp; 0 &amp;\frac{1}{7} &amp;\frac{4}{7}&amp;\frac{2}{7}&amp;0&amp; 0\\
\end{array}
</me>
For example, there are two vertices with degree four: vertex 6 and vertex 7.
</p>
</solution-->

				</p>
			</statement>
		</example>


</p>
</subsection>
<subsection xml:id="randvar2">
<title>Properties of a PMF</title>
<p>

The PMF of a random variable has the following properties.
		<ul>
			<li>
			<p>
  We always have
<me>
\sum_{t \in T} \P[ X = t] = 1.
</me>
			</p>
			</li>
			<li>
			<p>
 When <m>\Omega</m> is a finite set, we can find <m>\P[X = t]</m> by calculating
<me>
p(t) = \P[X=t] = \frac{ | \{ \omega \in \Omega | X(\omega) = t \} |} { | \Omega |}.
</me>
			</p>
			</li>
			<li>
			<p>
 A function <m>f: T \rightarrow \R</m> is a PMF if and only if
		<ul>
			<li>
			<p>
  <m>f(t) \geq 0</m> for all <m>t \in T</m>, and
			</p>
			</li>
			<li>
			<p>
  <m>\sum_{t \in T} f(t) = 1</m>.
			</p>
			</li>
		</ul>
			</p>
			</li>
		</ul>



</p>
</subsection>
</section>
<section xml:id="randvar3">
<title>Events</title>
<p>

A subset <m>A \subset \Omega</m> of the sample space is called an <em>event</em>. The <em>probability of event <m>A</m></em> is
<me>
\P(A) = \sum_{a \in A} p_X(a).
</me>
The subset <m>A</m> is called an "event" because we often give a description of the elements in <m>A</m> using some shared property, rather than directly listing the elements.


		<example>
			<title>Probability of Events</title>
			<statement>
				<p>
Suppose that we pick a random vertex from our example network.

			<image width="60%" xml:id="fig-img-randvar1" source="images/graph7.png" />


Let <m>A</m> be the event that the degree of the vertex is even. Let <m>B</m> be the event that the degree of the vertex is at least 3.
		<ul>
			<li>
			<p>
 List the elements of <m>A</m>, <m>B</m>, <m>A \cap B</m> and <m>A \cup B</m>.
			</p>
			</li>
			<li>
			<p>
 Next, calculate <m>\P[A]</m>, <m>\P[B]</m>, <m>\P[A \cap B]</m>  and <m>\P[A \cup B]</m>.
			</p>
			</li>
		</ul>

<!--solution>
<p>
<me>
A = \{ 1, 6, 7\} \qquad B = \{ 2, 3, 4, 5, 6, 7 \}
</me>

<me>
A\cap B = \{ 6, 7\} \qquad A \cup B = \{ 1,2,3,4,5,6,7\}
</me>

<me>
\P[A] = \frac{3}{7} \qquad \P[B] = \frac{6}{7} \qquad \P[A \cap B] = \frac{2}{7} \qquad \P[A \cup B] = 1
</me>
</p>
</solution-->

				</p>
			</statement>
		</example>


		<example>
			<title>Union of Events</title>
			<statement>
				<p>
For any sample space <m>\Omega</m> and  any events <m>A</m> and <m>B</m>, explain why
<me>
\P[A \cup B] = \P[A] + \P[B] - \P[A \cap B].
</me>


<!--solution>
<p>
This follows from the inclusion-exclusion formula
<me>
|A \cup B| = |A| +  |B| - |A \cap B|.
</me>
</p>
</solution-->

				</p>
			</statement>
		</example>




</p>
<subsection xml:id="randvar4">
<title>Conditional Probability</title>
<p>

Given two events <m>A, B \subset \Omega</m>, the <em>conditional probability of <m>A</m> given <m>B</m></em> is
<me>
\P[A \mid B] = \frac{\P[A \cap B]}{\P[B]}.
</me>
This is the probability of event <m>A</m>, given that event <m>B</m> is true.

		<example>
			<title>Conditional Probabillity</title>
			<statement>
				<p>
Pick a random vertex from our example network. Let's use the same events from the first example in this subsection:
		<ul>
			<li>
			<p>
 Let <m>A</m> be the event that the degree of the vertex is even.
			</p>
			</li>
			<li>
			<p>
 Let <m>B</m> be the event that the degree of the vertex is at least 3.
			</p>
			</li>
		</ul>
Calculate <m>\P[A \mid B]</m> and <m>\P[B \mid A]</m>.

			<image width="60%" xml:id="fig-img-randvar2" source="images/graph7.png" />

<!--solution>
<p>
<me>
\P[A \mid B] = \frac{2}{6} = \frac{1}{3} \qquad \mbox{and}  \qquad \P[B \mid A] = \frac{2}{3}
</me>
</p>
</solution-->


				</p>
			</statement>
		</example>

</p>
</subsection>
<subsection xml:id="randvar5">
<title>Independent Events and Dependent Events</title>
<p>

Two events <m>A,B \in \Omega</m> are <em>independent</em> when
<me>
\P[A \cap B] = \P[A] \P[B].
</me>
Otherwise, these events are dependent.


		<example>
			<title>Probability of Independent Events</title>
			<statement>
				<p>
Show that when <m>A</m> and <m>B</m> are independent, we have
<me>
\P[A \mid B ] = \P[A].
</me>
In other words, assuming that event <m>B</m> holds has no effect on the probability that event <m>A</m> holds.


<!--solution>
<p>
<me>
\P[A \mid B] = \frac{\P[A \cap B]}{\P[B]} = \frac{\P[A] \, \P[B]}{\P[B]} = \P[A].
</me>
</p>
</solution-->

				</p>
			</statement>
		</example>


		<example>
			<title>Example of Independent Events</title>
			<statement>
				<p>
Show that the events <m>A</m> and <m>B</m> from the network example problems above are dependent.

<!--solution>
<p>
We have
<me>
\P[A \cap B] = \frac{2}{7}  \qquad \mbox{ but } \qquad  \P[A] \P[B] = \frac{3}{7} \cdot \frac{6}{7} = \frac{18}{49}.
</me>
Since <m>\P[A \mid B] \neq \P[A]</m>, these are dependent events.
</p>
</solution-->

				</p>
			</statement>
		</example>




</p>
</subsection>
</section>
<section xml:id="randvar6">
<title>CDF and CCDF</title>
<p>

</p>
<subsection xml:id="randvar7">
<title>Cumulative Density Function</title>
<p>


The <em>cumulative distribution function (CDF)</em> <m>F_X: \R \rightarrow [0,1]</m> of a discrete random variable <m>X</m> is given by
<me>
F_X(t) = \P(X \leq t) = \sum_{k \leq t} p_X(k).
</me>
So the CDF <m>F_X(t)</m> captures the probability that the value of <m>X</m> is <em>at most</em> <m>t</m>, while the PMF <m>p_X(t)</m> captures the probability that the value of <m>X</m> is <em>exactly</em> <m>t</m>.

			</p><p>

		<example>
			<title>CDF for a Random Vertex Degree</title>
			<statement>
				<p>
Find the CDF for the random variable <m>X</m>, the degree of a randomly chosen vertex of our example network.

			<image width="60%" xml:id="fig-img-randvar3" source="images/graph7.png" />


<!--solution>
<p>
<me>
\begin{array}{c|c|c|c|c|c|c}
F_X(0) &amp; F_X(1) &amp; F_X(2) &amp; F_X(3) &amp; F_X(4) &amp; F_X(5) &amp; F_X(6) \\
\hline
\rule{0pt}{3.5ex} 0&amp;0&amp;\frac{1}{7}&amp;\frac{5}{7}&amp;1&amp;1&amp;1 \\
\end{array}
</me>
For example, among the 7 vertices, there are 5   vertices with degree at most 3,
</p>
</solution-->

				</p>
			</statement>
		</example>


			</p><p>



The CDF <m>F_X</m> of a discrete random variable satisfies the following properties:
		<ul>
			<li>
			<p>
 <m>F_X</m> is weakly increasing (aka monotonically nondecreasing). That is,
<me>
s \leq t \qquad \Longrightarrow  \qquad F_X(s) \leq F_X(t).
</me>
			</p>
			</li>
			<li>
			<p>
 <m>F_X(t)</m> tends to 0 as <m>t \rightarrow - \infty</m> , and tends to 1 as <m>t \rightarrow \infty</m>.
			</p>
			</li>
			<li>
			<p>
 Since <m>X</m> is a discrete random variable, the CDF <m>F_X(t)</m> is a piecewise constant function of <m>t</m>.
			</p>
			</li>
		</ul>


		<example>
			<title>Connecting the PMF with the CDF</title>
			<statement>
				<p>
Suppose that <m>X</m> takes on discrete integer values. Explain why
for any <m>k \in \Z</m>,
<me>
F_X(k) = \sum_{i=-\infty}^k p_X(i)
</me>
and
<me>
p_X(k) = F_X(k) - F_X(k-1).
</me>
In other words, if you know the PMF, then you can find the CDF, and vice versa.

<!--solution>
<p>
We have
<me>
F_X(k) = \sum_{i=-\infty}^k p_X(i)
</me>
because this is the definition of the CDF.
Therefore, we have
<me>
p_X(k) = F_X(k) - F_X(k-1) = \sum_{i=-\infty}^k p_X(i) - \sum_{i=-\infty}^{k-1} p_X(i) = p_X(k).
</me>
</p>
</solution-->

				</p>
			</statement>
		</example>







</p>
</subsection>
<subsection xml:id="randvar8">
<title>Complementary Cumulative Density Function</title>
<p>


The <em>complementary cumulative distribution function (CCDF)</em> <m>F_X: \R \rightarrow [0,1]</m> of a discrete random variable <m>X</m> is given by
<me>
\overline{F}_X(t) = \P(X &gt; t) = \sum_{k &gt; t} p_X(k) = 1 - F_X(t).
</me>
So the CCDF <m>\overline{F}_X(t)</m> captures the probability that the value of <m>X</m> is <em>greater than</em> <m>t</m>.

			</p><p>

		<example>
			<title>CCDF for Random Vertex Degree</title>
			<statement>
				<p>
Find the CCDF for the random variable <m>X</m> where, as above, the value of <m>X</m> is the degree of a randomly chosen vertex of our example network.

			<image width="60%" xml:id="fig-img-randvar4" source="images/graph7.png" />


<!--solution>
<p>
<me>
\begin{array}{c|c|c|c|c|c|c}
\overline{F}_X(0) &amp; \overline{F}_X(1) &amp; \overline{F}_X(2) &amp; \overline{F}_X(3) &amp; \overline{F}_X(4) &amp; \overline{F}_X(5) &amp; \overline{F}_X(6) \\
\hline
&amp;&amp;&amp;&amp;&amp;&amp; \\
1&amp;1&amp;\frac{6}{7}&amp;\frac{2}{7}&amp;0&amp;0&amp;0 \\
\end{array}
</me>
</p>
</solution-->

				</p>
			</statement>
		</example>



		<example>
			<title>Properties of a CCDF</title>
			<statement>
				<p>
Using the fact that <m>\overline{F}_X(t) = 1 - F_X(t)</m>, write down the properties of a CCDF that are analogous to the CDF properties  listed above.

<!--solution>
<p>
The CCDF <m>\overline{F}_X</m> of a discrete random variable satisfies the following properties:
		<ul>
			<li>
			<p>
 <m>\overline{F}_X</m> is weakly decreasing (aka monotonically nonincreasing). That is,
<me>
s \leq t \qquad \Longrightarrow  \qquad \overline{F}_X(s) \geq \overline{F}_X(t).
</me>
			</p>
			</li>
			<li>
			<p>
 <m>\overline{F}_X(t)</m> tends to 1 as <m>t \rightarrow - \infty</m> , and tends to 0 as <m>t \rightarrow \infty</m>.
			</p>
			</li>
			<li>
			<p>
 Since <m>X</m> is a discrete random variable, the CCDF <m>\overline{F}_X(t)</m> is a piecewise constant function of <m>t</m>.
			</p>
			</li>
		</ul>

</p>
</solution-->

				</p>
			</statement>
		</example>




		<example>
			<title>Connecting the PMF and the CCDF</title>
			<statement>
				<p>
Suppose that <m>X</m> takes on discrete integer values. Develop formulas for going back and forth between the PMF and the CCDF (analogous to how you connected the PMF and CDF above).


<!--solution>
<p>


For any <m>k \in \Z</m>,
<me>
\overline{F}_X(k) = \sum_{i=k+1}^{\infty} p_X(i)
</me>
by the definition of a CCDF. We then have
<me>
\overline{F}_X(k-1) -  \overline{F}_X(k)= \sum_{i=k}^{\infty} p_X(i) - \sum_{i=k+1}^{\infty} p_X(i) =
p_X(k).
</me>
In other words, if you know the PMF, then you can find the CCDF, and vice versa.

</p>
</solution-->

				</p>
			</statement>
		</example>




</p>
</subsection>
<subsection xml:id="randvar9">
<title>Example: The Sum of Two Dice</title>
<p>

Let's run an experiment where <m>X</m> is the outcome when we roll two fair 6-sided dice.

		<example>
			<title>Sum of Two Dice</title>
			<statement>
				<p>
Find the values of PMF <m>p(t) = p_X(t)</m>, CDF <m>F(t) = F_X(t)</m> and CCDF <m>\overline{F}(t) = \overline{F}_X(t)</m>. Use the domain <m>0 \leq t \leq 12</m> for each.

<!--solution>
<p>



<me>
\begin{array}{c|c|c|c|c|c|c|c|c|c|c|c|c}
p(0) &amp; p(1) &amp; p(2) &amp; p(3) &amp; p(4) &amp; p(5) &amp; p(6) &amp;
p(7) &amp; p(8) &amp; p(9) &amp; p(10) &amp; p(11) &amp; p(12)
\\
\hline
&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp; \\
0&amp;0&amp;\frac{1}{36}&amp;\frac{2}{36}&amp;\frac{3}{36}&amp;\frac{4}{36}&amp;\frac{5}{36}&amp;\frac{6}{36}&amp;\frac{5}{36}&amp;\frac{4}{36}&amp;\frac{3}{36}&amp;\frac{2}{36}&amp;\frac{1}{36} \\
\end{array}
</me>


			</p><p>


<me>
\begin{array}{c|c|c|c|c|c|c|c|c|c|c|c|c}
F(0) &amp; F(1) &amp; F(2) &amp; F(3) &amp; F(4) &amp; F(5) &amp; F(6) &amp;
F(7) &amp; F(8) &amp; F(9) &amp; F(10) &amp; F(11) &amp; F(12)
\\
\hline
&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp; \\
0&amp;0&amp;\frac{1}{36}&amp;\frac{3}{36}&amp;\frac{6}{36}&amp;\frac{10}{36}&amp;\frac{15}{36}&amp;\frac{21}{36}&amp;\frac{26}{36}&amp;\frac{30}{36}&amp;\frac{33}{36}&amp;\frac{35}{36}&amp;1 \\
\end{array}
</me>



			</p><p>


<me>
\begin{array}{c|c|c|c|c|c|c|c|c|c|c|c|c}
\overline{F}(0) &amp; \overline{F}(1) &amp; \overline{F}(2) &amp; \overline{F}(3) &amp; \overline{F}(4) &amp; \overline{F}(5) &amp; \overline{F}(6) &amp;
\overline{F}(7) &amp; \overline{F}(8) &amp; \overline{F}(9) &amp; \overline{F}(10) &amp; \overline{F}(11) &amp; \overline{F}(12)
\\
\hline
&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp; \\
1&amp; 1&amp;\frac{35}{36}&amp;\frac{33}{36}&amp;\frac{30}{36}&amp;\frac{26}{36}&amp;\frac{21}{36}&amp;\frac{15}{36}&amp;\frac{10}{36}&amp;\frac{6}{36}&amp;\frac{3}{36}&amp;\frac{1}{36}&amp;0 \\
\end{array}
</me>



</p>
</solution-->




				</p>
			</statement>
		</example>

		<example>
			<title>Sketching PMF, CDF, CCDF for Two Dice</title>
			<statement>
				<p>
Sketch the graphs of the PMF, CDF and CCDF. Make any observations that you can about how these graphs are related.



		<ul>
			<li>
			<p>
 PMF  <m>\qquad p(t)</m>

			<image width="50%" xml:id="fig-img-randvar5">
				<latex-image>
\begin{tikzpicture}[scale=.5, axis line style/.style={thick, -stealth}]

\begin{scope}

\draw [axis line style] (0,0) z-z-z (12.5,0);
\draw [axis line style] (0,0) z-z-z (0,7.5);



\foreach \x in {1,...,12} {
\draw[gray] (\x,0) z-z-z (\x,7);
\draw (<m>(\x,0) + (0,-2pt)</m>) z-z-z (<m>(\x,0) + (0,2pt)</m>)
node [below] {<m>\x</m>};

}

\foreach \y in {.25, .5, .75, 1} {
\draw[gray] (0,\y*7) z-z-z (12,\y*7);
\draw (<m>(0,\y*7) + (-2pt,0)</m>) z-z-z (<m>(0,\y*7) + (2pt,0)</m>)
node [left] {<m>\y</m>};
}

\end{scope}

\end{tikzpicture}
				</latex-image>
			</image>




			</p>
			</li>
			<li>
			<p>
 CDF  <m>\qquad F(t) = \P(X \leq t) = \sum_{k \leq t} p(k).</m>


			<image width="50%" xml:id="fig-img-randvar6">
				<latex-image>
\begin{tikzpicture}[scale=.5, axis line style/.style={thick, -stealth}]

\begin{scope}

\draw [axis line style] (0,0) z-z-z (12.5,0);
\draw [axis line style] (0,0) z-z-z (0,7.5);



\foreach \x in {1,...,12} {
\draw[gray] (\x,0) z-z-z (\x,7);
\draw (<m>(\x,0) + (0,-2pt)</m>) z-z-z (<m>(\x,0) + (0,2pt)</m>)
node [below] {<m>\x</m>};

}

\foreach \y in {.25, .5, .75, 1} {
\draw[gray] (0,\y*7) z-z-z (12,\y*7);
\draw (<m>(0,\y*7) + (-2pt,0)</m>) z-z-z (<m>(0,\y*7) + (2pt,0)</m>)
node [left] {<m>\y</m>};
}

\end{scope}

\end{tikzpicture}
				</latex-image>
			</image>




			</p>
			</li>
			<li>
			<p>
 CCDF  <m>\qquad  \overline{F}(t) = \P(X &gt; t) = \sum_{k &gt; t} p(k) = 1 - F(t)</m>

			<image width="50%" xml:id="fig-img-randvar7">
				<latex-image>
\begin{tikzpicture}[scale=.5, axis line style/.style={thick, -stealth}]

\begin{scope}

\draw [axis line style] (0,0) z-z-z (12.5,0);
\draw [axis line style] (0,0) z-z-z (0,7.5);



\foreach \x in {1,...,12} {
\draw[gray] (\x,0) z-z-z (\x,7);
\draw (<m>(\x,0) + (0,-2pt)</m>) z-z-z (<m>(\x,0) + (0,2pt)</m>)
node [below] {<m>\x</m>};

}

\foreach \y in {.25, .5, .75, 1} {
\draw[gray] (0,\y*7) z-z-z (12,\y*7);
\draw (<m>(0,\y*7) + (-2pt,0)</m>) z-z-z (<m>(0,\y*7) + (2pt,0)</m>)
node [left] {<m>\y</m>};
}

\end{scope}

\end{tikzpicture}
				</latex-image>
			</image>


			</p>
			</li>
		</ul>




<!--solution>
<p>

The following graphs are drawn to the same scale. The <m>x</m>-axis  spans <m>[0,12]</m> and the <m>y</m>-axis spans <m>[0,1]</m>.

			<image width="70%" xml:id="fig-img-randvar8">
				<latex-image>
\begin{tikzpicture}[scale=.5,axis line style/.style={thick, -stealth}] %mathbook width=70%


\begin{scope}

\draw [axis line style] (0,0) z-z-z (12.5,0);
\draw [axis line style] (0,0) z-z-z (0,7.5);


\node at (15,3.5) {PMF};

\foreach \x in {1,...,12} {
\draw[gray] (\x,0) z-z-z (\x,7);
\draw (<m>(\x,0) + (0,-2pt)</m>) z-z-z (<m>(\x,0) + (0,2pt)</m>)
node [below] {<m>\x</m>};

}

\foreach \y in {.25, .5, .75, 1} {
\draw[gray] (0,\y*7) z-z-z (12,\y*7);
\draw (<m>(0,\y*7) + (-2pt,0)</m>) z-z-z (<m>(0,\y*7) + (2pt,0)</m>)
node [left] {<m>\y</m>};
}

\draw[very thick, blue]
(0,0) z-z-z (1,0) z-z-z (2,7*1/36) z-z-z ( 3,7*2/36) z-z-z (4 ,7*3/36) z-z-z ( 5,7*4/36) z-z-z (6 ,7*5/36) z-z-z (7 ,7*6/36) z-z-z ( 8,7*5/36) z-z-z (9 ,7*4/36) z-z-z (10 ,7*3/36) z-z-z (11 ,7*2/36) z-z-z (12 ,7*1/36);

\end{scope}



\begin{scope}[shift={(0,-10)}]

\draw [axis line style] (0,0) z-z-z (12.5,0);
\draw [axis line style] (0,0) z-z-z (0,7.5);


\node at (15,3.5) {CDF};


\foreach \x in {1,...,12} {
\draw[gray] (\x,0) z-z-z (\x,7);
\draw (<m>(\x,0) + (0,-2pt)</m>) z-z-z (<m>(\x,0) + (0,2pt)</m>)
node [below] {<m>\x</m>};

}

\foreach \y in {.25, .5, .75, 1} {
\draw[gray] (0,\y*7) z-z-z (12,\y*7);
\draw (<m>(0,\y*7) + (-2pt,0)</m>) z-z-z (<m>(0,\y*7) + (2pt,0)</m>)
node [left] {<m>\y</m>};
}

\draw[very thick, blue]
(0,0) z-z-z (1,0) z-z-z (2,7*1/36) z-z-z ( 3,7*3/36) z-z-z (4 ,7*6/36) z-z-z ( 5,7*10/36) z-z-z (6 ,7*15/36) z-z-z (7 ,7*21/36) z-z-z ( 8,7*26/36) z-z-z (9 ,7*30/36) z-z-z (10 ,7*33/36) z-z-z (11 ,7*35/36) z-z-z (12 ,7*36/36);


\end{scope}

\begin{scope}[shift={(0,-20)}]

\draw [axis line style] (0,0) z-z-z (12.5,0);
\draw [axis line style] (0,0) z-z-z (0,7.5);


\node at (15,3.5) {CCDF };


\foreach \x in {1,...,12} {
\draw[gray] (\x,0) z-z-z (\x,7);
\draw (<m>(\x,0) + (0,-2pt)</m>) z-z-z (<m>(\x,0) + (0,2pt)</m>)
node [below] {<m>\x</m>};

}

\foreach \y in {.25, .5, .75, 1} {
\draw[gray] (0,\y*7) z-z-z (12,\y*7);
\draw (<m>(0,\y*7) + (-2pt,0)</m>) z-z-z (<m>(0,\y*7) + (2pt,0)</m>)
node [left] {<m>\y</m>};
}

\draw[very thick, blue]
(0,7*1) z-z-z (1,7*1) z-z-z (2,7*35/36) z-z-z ( 3,7*33/36) z-z-z (4 ,7*30/36) z-z-z ( 5,7*26/36) z-z-z (6 ,7*21/36) z-z-z (7 ,7*15/36) z-z-z ( 8,7*10/36) z-z-z (9 ,7*6/36) z-z-z (10 ,7*3/36) z-z-z (11 ,7*1/36) z-z-z (12 ,7*0/36);

\end{scope}

\end{tikzpicture}
				</latex-image>
			</image>



</p>
</solution-->



				</p>
			</statement>
		</example>

</p>
</subsection>
</section>
<section xml:id="randvar10">
<title>Expectation, Variance and Moments</title>
<p>

</p>
<subsection xml:id="randvar11">
<title>Expected Value</title>
<p>

The <em>expected value</em> of a discrete random variable is
The <em>expected value</em> of a discrete random variable is
<me>
\E[X] = \sum_{\omega \in \Omega} X(\omega) p(\omega)
</me>
which is equivalent to
<me>
\E[X] = \sum_{t \in T} t \cdot p(t) = \sum_{t \in T}  t \cdot \P[X=t].
</me>


		<example>
			<title>Expected Value for Vertex Degree</title>
			<statement>
				<p>
Find <m>\E[X]</m> when <m>X</m> is the degree  a randomly chosen vertex of our example network.

			<image width="60%" xml:id="fig-img-randvar9" source="images/graph7.png" />


<!--solution>
<p>
<me>
\E[X] = 2 \cdot \frac{1}{7} + 3 \cdot \frac{4}{7} + 4 \cdot \frac{2}{7} = \frac{22}{7}
</me>
</p>
</solution-->


				</p>
			</statement>
		</example>

		<example>
			<title>Expected Value for Dice Roll</title>
			<statement>
				<p>
Find <m>\E[X]</m> when <m>X</m> is the outcome when you roll two fair dice.


<!--solution>
<p>
Let's use linearity of expectation (from the next exercise). Let <m>Y</m> be the outcome when we roll one fair die. We have
<me>
\E[Y] = \frac{1}{6} \left( 1 + 2 + 3 + 4 + 5 + 6 \right) = \frac{21}{6} = \frac{7}{2}.
</me>
When we roll two dice, we have
<me>
\E[X] =  \E[Y_1] + \E[Y_2] = \frac{7}{2} + \frac{7}{2} = 7.
</me>
where both <m>Y_1</m> and <m>Y_2</m> are the outcome of rolling one fair die.
</p>
</solution-->

				</p>
			</statement>
		</example>


</p>
</subsection>
<subsection xml:id="randvar12">
<title>Linearity of Expectation</title>
<p>

		<example>
			<title>Linearity of Expectation</title>
			<statement>
				<p>
Prove that if <m>X</m> and <m>Y</m> are two random variables and <m>a, b \in \R</m>, then we have the following <em>linearity of expectation</em> formula:
<me>
\E[a X + b Y] = a \E[X] + b \E[Y].
</me>

<!--solution>
<p>
We have
</p>
<md>
<mrow>
\E[aX+bY] &amp;= \sum_{\omega  \in \Omega} (aX(\omega) + bY(\omega) ) p(\omega)
</mrow>
<mrow>
&amp;= a \sum_{\omega  \in \Omega} X(\omega)p(\omega)  + b \sum_{\omega  \in \Omega} Y(\omega)p(\omega)
</mrow>
<mrow>
&amp;=a \E[X] + b \E[Y].
</mrow>
</md>
<p>
</p>
</solution-->

				</p>
			</statement>
		</example>




</p>
</subsection>
<subsection xml:id="randvar13">
<title>Variance</title>
<p>

The <em>variance</em> <m>\var(X)</m> is given by
<me>
\var(X) = \E \left[ (X - \E[X])^2 \right] = \sum_{t \in T} \left( t - \E[X] \right)^2 p(t).
</me>
The variance is  a measure of dispersion of <m>X</m> around its expected value. It is always nonnegative.

		<example>
			<title>Formula for Variance</title>
			<statement>
				<p>
Show that
<me>
\var(X) = \E[X^2] - (\E[X])^2.
</me>


<!--solution>
<p>

Here  is the argument. The notation is a little dense, so read it slowly. Each step has a simple explanation. For example,
<me>
\E[\E[X]] = \E[X]
</me>
because <m>\E[X]</m> is just a constant. (For the same reason, <m>\E[13] = 13</m> because the value doesn't change as we consider elements of the state space.)
</p>
<md>
<mrow>
\var(X) &amp;=  \E \left[ (X - \E[X])^2 \right]
\, = \, \E[ X^2 -2 X \, \E[X] + \E[X]^2]
</mrow>
<mrow>
&amp;=   \E[ X^2] -\E[2 X \, \E[X]] + \E[\E[X]^2] \, = \, \E[ X^2] -2 \E[X] \, \E[X ] + (\E[X])^2
</mrow>
<mrow>
&amp;=  \E[X^2] - (\E[X])^2
</mrow>
</md>
<p>
where we have used linearity of expectation.

</p>
</solution-->

				</p>
			</statement>
		</example>



		<example>
			<title>Variance for a Random Vertex Degree</title>
			<statement>
				<p>
Calculate the variance of our running example where <m>X</m> is the degree of a randomly chosen vertex from this network.

			<image width="60%" xml:id="fig-img-randvar10" source="images/graph7.png" />



<!--solution>
<p>


<me>
\E[X] = \frac{22}{7}
</me>
and
<me>
\E[X^2] = 2^2 \cdot \frac{1}{7} + 3^2 \cdot \frac{4}{7} + 4^2 \cdot \frac{2}{7}
= \frac{4+36+32}{7} = \frac{72}{7}
</me>
and therefore
<me>
\var(X) = \E[X^2] - \E[X]^2 =  \frac{72}{7} - \left( \frac{22}{7} \right)^2 = \frac{20}{49}.
</me>

</p>
</solution-->

				</p>
			</statement>
		</example>


</p>
</subsection>
<subsection xml:id="randvar14">
<title>Standard Deviation</title>
<p>


The <em>standard deviation</em>
<me>
\sigma = \sqrt{ \var(X) }
</me>
has the same units as the random variable <m>X</m>, so it is easier to interpret than <m>\var(X)</m>. It can be shown that <m>75</m> percent of the sample space satisfies
<me>
\mu - 2 \sigma  \leq X \leq \mu + 2\sigma.
</me>
This is why the standard deviation is a measure of the concentration around the expected value.

</p>
</subsection>
<subsection xml:id="randvar15">
<title>The <m>k</m>th Moment</title>
<p>

The <em><m>k</m>th moment</em> of the random variable <m>X</m> is <m></m>\E[X^k],<m></m>
the expected value of <m>X^k</m>. The <em><m>k</m>th central moment</em> is
<me>
\E \left[ ( X - \E[X])^k \right].
</me>
So the second central moment is the variance, <m>\var(X)</m>. The third central moment is the <em>skewness</em>, which measures the asymmetry of the PMF. The fourth central moment its the <em>kurtosis</em>, which measures the "peakness" of the PMF (tall and skinny versus short and squat). We will mostly be interested in variance and the second moment.








</p>
</subsection>
</section>
<section xml:id="randvar16">
<title>Famous Discrete Distributions</title>
<p>

Here are three discrete random variables that will be useful when we talk about random models for complex networks. You will prove the formulas and explore their properties in the exercises.



</p>
<subsection xml:id="randvar17">
<title>Binomial Distribution</title>
<p>


Flip a weighted coin <m>n</m> times, where <m>p</m> is the probability of obtaining heads, and <m>1-p</m> is the probability of obtaining tails. Define <m>X</m> to be the number of heads in the <m>n</m> tosses. This is the <em>binomial random variable with parameters <m>n</m> and <m>p</m></em>.


The PMF is
<me>
p(k) = {n \choose k} p^k (1 - p)^{n-k}.
</me>
The  expectation is
<me>
E[X] = np.
</me>
The variance is
<me>
\var(X) = np(1-p).
</me>
Here are the PMF and CDF of a binomial random variable.

</p>
<table>
<tabular top="minor" left="minor" bottom="minor" right="minor">
<row>
<cell>
			<image width="45%" xml:id="fig-img-randvar11" source="images/Binomial_pmf.png" />
</cell>
<cell>

</cell>
<cell>
			<image width="45%" xml:id="fig-img-randvar12" source="images/Binomial_cdf.png" />
</cell>
</row>
<row>
<cell>
PMF
</cell>
<cell>

</cell>
<cell>
CDF
</cell>
</row>
</tabular>
</table>
<p>


</p>
</subsection>
<subsection xml:id="randvar18">
<title>Geometric Distribution</title>
<p>


Once again, we have a weighted coin where <m>p</m> is the probability of obtaining heads, and <m>1-p</m> is the probability of obtaining tails. Instead of flipping our coin for a fixed number of times, we will flip it until we first encounter a heads. This experiment gives the geometric random variable <m>Y</m>. . This is the <em>geometric random variable for <m>p</m></em>.




The PMF is
<me>
p(k) =  (1 - p)^{k-1}  p.
</me>
The  expectation is
<me>
E[Y] = \frac{1}{p}.
</me>
The variance is
<me>
\var(Y) = \frac{1-p}{p^2}
</me>
Here are the PMF and CDF of a geometric random variable

</p>
<table>
<tabular top="minor" left="minor" bottom="minor" right="minor">
<row>
<cell>
			<image width="45%" xml:id="fig-img-randvar13" source="images/Geo_pmf.png" />
</cell>
<cell>

</cell>
<cell>
			<image width="45%" xml:id="fig-img-randvar14" source="images/Geo_cdf.png" />
</cell>
</row>
<row>
<cell>
PMF
</cell>
<cell>

</cell>
<cell>
CDF
</cell>
</row>
</tabular>
</table>
<p>


</p>
</subsection>
<subsection xml:id="randvar19">
<title>Poisson Distribution</title>
<p>


The Poisson random variable <m>Z</m> for parameter <m>\lambda &gt; 0</m> has PMF given by
<me>
p(k) = e^{-\lambda} \frac{\lambda^k}{k!}.
</me>
The  expectation is
<me>
E[Z] =  \lambda
</me>
The variance is
<me>
\var(Z) =  \lambda
</me>
Here are the PMF and CDF of a poisson random variable.

</p>
<table>
<tabular top="minor" left="minor" bottom="minor" right="minor">
<row>
<cell>
			<image width="45%" xml:id="fig-img-randvar15" source="images/Poisson_pmf.png" />
</cell>
<cell>

</cell>
<cell>
			<image width="45%" xml:id="fig-img-randvar16" source="images/Poisson_cdf.png" />
</cell>
</row>
<row>
<cell>
PMF
</cell>
<cell>

</cell>
<cell>
CDF
</cell>
<cell>

</cell>
</row>
</tabular>
</table>
<p>







</p>
</subsection>
</section>







	<exercises>
		<title>Practice Problems</title>


		<exercise>
			<title>Probability Concept Review</title>
			<idx><h>Probability Concept Review</h></idx>
			<statement>
				<p>
Provide the definition and/or formula for each of the following terms. Then give an "intuitive description" of what this concept tells us, and why we might care. An illustrating concrete example (say, about vertex degrees in a network) can be a better way  convey your understanding than simply speaking in generalities.

			<ol>
				<li>
					<p>
 A random variable <m>X : \Omega \rightarrow \Z_{\geq 0}</m>.
					</p>
				</li>
				<li>
					<p>
 The probability mass function (PMF) <m>p_X(t)</m>.
					</p>
				</li>
				<li>
					<p>
 The expected value <m>\E[X]</m>.
					</p>
				</li>
				<li>
					<p>
 The variance <m>\var[X]</m>.

					</p>
				</li>
			</ol>

<!--solution>
<p>
			<ol>

				<li>
					<p>
 A random variable <m>X : \Omega \rightarrow \Z_{\geq 0}</m> is a function on the set <m>\Omega</m> of outcomes of an experiment.  We pick a sample outcome and measure one of its property. For example, we could pick a vertex of a network and write down its degree.

			</p><p>

This is useful when I want to get a sense of the structure (or typical structure) of a network, or another system.

					</p>
				</li>
				<li>
					<p>
 For <m>t \in \Z_{\geq 0}</m>, the value <m>p_X(t)</m> is the probability that <m>X=t</m> when we perform our experiment. For example, the PMF of "measure the degree of a randomly chosen vertex" is
<me>
p(t) = \frac{\mbox{number of vertices of degree <m>t</m>}}{\mbox{total number of vertices}}
</me>

			</p><p>
The PMF gives me a sense of what outcomes are possible, and how likely they are compared to one another.

					</p>
				</li>
				<li>
					<p>
 The expected value is
<me>
\E[X] = \sum_{t=0}^{\infty} t \cdot p_X(t)
</me>
is weighted average of all possible outcomes, using the PMF <m>p_X(t)</m> as the weight for outcome <m>X=t</m>.

			</p><p>
If I repeat my experiment many, many times, then the average outcome value of my experiment will be a number close to the expected value. However, any one particular outcome might be very far away from the average value.

			</p><p>
For example, knowing the average degree could be helpful when thinking about degree centrality. I can assess whether a given vertex has large degree or small degree in the spectrum of observed values.

					</p>
				</li>
				<li>
					<p>
 The variance is
<me>
\var[X] = E[X^2] - E[X]^2.
</me>
This number tells me about the "spread" of the distribution around its average value. A small variance means that the PMF is concentrated around the average value, so most of my experiments will return a value that is close to the average one. A large variance means that the values are more spread out.

			</p><p>

Taking the square root gives you the standard deviation <m>\sigma = \sqrt{\var[X]}</m>. We can compare this value directly to the expected value, since they have the same units. This helps to get a sense of whether the variance is "big" or "small." Comparing standard deviation to the expected value helps to give us some sense of scale.

			</p><p>
For example, in a graph with small variance, most of the vertices have similar degrees. In a graph with high variance, we will have a much more diverse collection of vertex degrees. In particular, there will be some vertices with much smaller degrees than typical, or some vertices with much larger degree than typical, or both.

					</p>
				</li>
			</ol>
</p>
</solution-->




			</p><p>
Now that  these concepts are at your fingertips, let's explore
three distributions that will  appear frequently in our discussion of network models and dynamic network processes. In the questions that follow, take some time to reflect on the formulas (as well as the techniques that got you there). For each question:
		<ul>
			<li>
			<p>
 Perform the calculation
			</p>
			</li>
			<li>
			<p>
 Pause to think about what the formula means.
			</p>
			</li>
			<li>
			<p>
 Interpret what the answer would mean for large <m>n</m>; for different values of <m>p \in [0,1]</m>; for big or small <m>k</m>.

			</p>
			</li>
		</ul>



				</p>
			</statement>
		</exercise>
		<exercise>
			<title>Binomial Random Variable</title>
			<idx><h>Binomial Random Variable</h></idx>
			<statement>
				<p>
Flip a weighted coin <m>n</m> times, where <m>p</m> is the probability of obtaining heads, and <m>1-p</m> is the probability of obtaining tails. Define <m>X</m> to be the number of heads in the <m>n</m> tosses. This is the <em>binomial random variable with parameters <m>n</m> and <m>p</m></em>.

			<ol>
				<li>
					<p>
 Give a combinatorial argument for why the PMF of the binomial random variable is
<me>
p(k) = {n \choose k} p^k (1 - p)^{n-k}.
</me>

<!--solution>
<p>
We give a combinatorial recipe.
		<ul>
			<li>
			<p>
 Pick the <m>k</m> flips that will be <m>H</m>. There are <m>{n \choose k}</m> ways to do so.
			</p>
			</li>
			<li>
			<p>
 The probability that the chosen <m>k</m> flips all turn up <m>H</m> is <m>p^k</m>.
			</p>
			</li>
			<li>
			<p>
 The probability that the remaining <m>n-k</m> flips all turn up <m>T</m> is <m>(1-p)^{n-k}</m>.
			</p>
			</li>
		</ul>
Multiplying all these terms together gives the expression above.
</p>
</solution-->


					</p>
				</li>
				<li>
					<p>
 Use the binomial theorem
<me>
(x+y)^n = \sum_{k=0}^n {n \choose k} x^ky^{n-k}
</me>
to prove that <m>p(k)</m> is a PMF.


<!--solution>
<p>
First, we note that <m>0 \leq p(k) \leq 1</m> for <m>0 \leq k \leq n</m>. Next, we must prove that the probabilities all sum to one. This follows quickly from the binomial theorem with <m>x=p</m> and <m>y=1-p</m>:
<me>
\sum_{k=0}^n {n \choose k} p^k (1-p)^{n-k} = (p + (1-p))^n = 1^n = 1.
</me>
</p>
</solution-->

					</p>
				</li>
				<li>
					<p>
 Linearity of expectation applies to the sum of multiple random variables. In particular, an easy proof by induction shows that for any random variables <m>X_1, X_2, \ldots, X_n</m>, we have
<me>
\E[X_1 + X_2 + \cdots + X_n] = \E[X_1] + \E[X_2] + \cdots + \E[X_n]
</me>
Use this formula to show that
<me>
\E[X] = np.
</me>
You will have to split your random variable <m>X</m> into the sum of <m>n</m> random variables.
(Note: you can also prove this directly from part (a), but it is a bit tedious.)




<!--solution>
<p>

Let <m>X_i</m> be an "indicator function" for whether coin <m>i</m> is <m>H</m>. That is,
<me>
X_i = \left\{
\begin{array}{cc}
1 &amp; \mbox{if the } i\mbox{th coin is } H, \\
0 &amp;  \mbox{if the } i\mbox{th coin is } T. \\
\end{array}
\right.
</me>
Then
<me>
\E[X] = \E\left[ \sum_{i=1}^n X_i \right] = \sum_{i=1}^n \E[X_i] =  \sum_{i=1}^n p = np.
</me>


For comparison, here is a proof that does not use linearity of expectation. It isn't "hard" but it does take a bit of work. Our strategy will be to
factor out an <m>n</m> and then reindex the sum.
</p>
<md>
<mrow>
\E[X] &amp;= \sum_{k=0}^n k p(k)
\, = \,  \sum_{k=0}^n k {n \choose k} p^k (1-p)^{n-k}
</mrow>
<mrow>
&amp; =  \sum_{k=1}^n  \frac{n!}{(k-1)! (n-k)!} p^k (1-p)^{n-k}
</mrow>
<mrow>
&amp; =  np \sum_{k=1}^n  \frac{(n-1)!}{(k-1)! (n-k)!} p^{k-1} (1-p)^{n-k}
</mrow>
<mrow>
&amp; =  np \sum_{j=0}^{n-1}  \frac{(n-1)!}{j! (n-1-j)!} p^{j} (1-p)^{n-1-j}
</mrow>
<mrow>
&amp;= np \sum_{j=0}^{n-1}  {n-1 \choose j}  p^{j} (1-p)^{n-1-j}
</mrow>
<mrow>
&amp; =  np  (p + (1-p))^{n-1} \, = \,  np.
</mrow>
</md>
<p>
We use a couple of tricks here
		<ul>
			<li>
			<p>
 At the third equality, we replace the lower limit of <m>k=0</m> with <m>k=1</m>. This is because the <m>k=0</m> term equals 0, so we do not need to list it. <em>This is an important step!</em> Do not underestimate the need to properly account for the lowest/highest index.
			</p>
			</li>
			<li>
			<p>
 At the fifth equality, we reindex, using <m>j</m> instead of <m>k</m>. <em>Do this carefully!</em> In my margin, I always write down the substitution in two ways. Here we are using <m>j=k-1</m>, which is the same as <m>k=j+1</m>. Having both of these expression staring at me will ensure that I don't make mistakes during the reindexing. Wherever I see a "<m>k</m>," I replace it with a "<m>j+1</m>." Or if I want to be fancy, I can immediately replace a "<m>k-1</m>" with a "<m>j</m>."
			</p>
			</li>
		</ul>
Don't cut corners on these substitutions. You will save yourself a lot of headaches!
</p>
</solution-->


					</p>
				</li>
				<li>
					<p>
 <em>[Do not solve this one. It is a long calculation.]</em> It can be shown that
<me>
\var(X) = np(1-p).
</me>
But you do not need to do this here. You need to use the fact that
<me>
\E[X^2] = \E[X(X-1) + X] = \E[X(X-1)] + \E[X],
</me>
which follows from <em>linearity of expectation</em>.

<!--solution>
<p>
This plays out much like "tedious calculation" in the answer to part (c), but it is more involved. We want to calculate
</p>
<md>
<mrow>
\E[X^2] - (\E[X])^2 &amp;= \E[X(X-1) + X] - (\E[X])^2
</mrow>
<mrow>
&amp;= \E[X(X-1)] + \E[X] - (\E[X])^2
</mrow>
</md>
<p>
Of these three terms, we already know that <m>\E[X]=np</m> and that <m>(E[X])^2 =  (np)^2</m>. So we only need to calculate <m>\E[X(X-1)] </m>. Here we go. This time, we will reindex using <m>j=k-2</m>, or equivalently, <m>k=j+2</m>.

</p>
<md>
<mrow>
\E[X(X-1)] &amp;= \sum_{k=0}^n k(k-1) p(k) \, = \, \sum_{k=0}^n  k(k-1) {n \choose k} p^k (1-p)^{n-k}
</mrow>
<mrow>
&amp; =  \sum_{k=2}^n  \frac{n!}{(k-2)! (n-k)!} p^k (1-p)^{n-k}
</mrow>
<mrow>
&amp;=  n(n-1)p^2 \sum_{k=2}^n  \frac{(n-2)!}{(k-1)! (n-k)!} p^{k-2} (1-p)^{n-k}
</mrow>
<mrow>
&amp; =  n(n-1)p^2  \sum_{j=0}^{n-2}  \frac{(n-2)!}{j! (n-2-j)!} p^{j} (1-p)^{n-2-j}
</mrow>
<mrow>
&amp;= n(n-1)p^2 \sum_{j=0}^{n-2}  {n-2 \choose j}  p^{j} (1-p)^{n-2-j}
</mrow>
<mrow>
&amp; =  n(n-1)p^2  (p + (1-p))^{n-2} \, = \,  n(n-1)p^2.
</mrow>
</md>
<p>
We are now ready to put it together:
</p>
<md>
<mrow>
\E[X^2] - (\E[X])^2 &amp;= n(n-1)p^2 + np -(np)^2
</mrow>
<mrow>
&amp;= (np)^2 - np^2 + np - (np)^2
</mrow>
<mrow>
&amp;= np(1-p).
</mrow>
</md>
<p>
</p>
</solution-->

					</p>
				</li>
			</ol>




				</p>
			</statement>
		</exercise>
		<exercise>
			<title>Geometric Random Variable</title>
			<idx><h>Geometric Random Variable</h></idx>
			<statement>
				<p>
Instead of flipping our coin for a fixed number of times, we will flip it until we first encounter a heads. This experiment gives the geometric random variable <m>Y</m>.



			<ol>
				<li>
					<p>
 Give a combinatorial argument for  why the PMF of the geometric random variable is
<me>
p(k) =  (1 - p)^{k-1}  p.
</me>

<!--solution>
<p>
In order for the <m>k</m>th flip to be the first <m>H</m> that we encounter, we must obtain <m>k-1</m> <m>T</m>'s in a row, followed by a <m>H</m>. The probability of this event is <m>(1-p)^{k-1}p</m>. Note that <m>p(0) = 0</m> since we cannot stop until we have seen a <m>H</m>.
</p>
</solution-->

					</p>
				</li>
				<li>
					<p>
 Use the fact that
<me>
\sum_{k=0}^{\infty} x^k = \frac{1}{1-x}
</me>
to prove that  <m>p(k)</m> is a PMF.

<!--solution>
<p>
It is easy to see that <m>0 \leq p(k) \leq 1</m> for all <m>k \in \Z^+</m>. Now we must show that the probabilities sum to 1. We have
</p>
<md>
<mrow>
\sum_{k=1}^{\infty} p(k) &amp;= \sum_{k=1}^{\infty} (1-p)^{k-1} p \, = \, p \sum_{k=1}^{\infty} (1-p)^{k-1}
</mrow>
<mrow>
&amp;= p \sum_{j=0}^{\infty} (1-p)^{j} \, = \, \frac{p}{1 - (1-p)} \,=\, \frac{p}{p} \,=\, 1.
</mrow>
</md>
<p>

</p>
</solution-->

					</p>
				</li>
				<li>
					<p>
 Show that
<me>
\E[Y] = \frac{1}{p}.
</me>
Hint: take the derivative of both sides of the equality in part (b) to get a new identity.

<!--solution>
<p>
We have
<me>
\E[Y] = \sum_{k=1}^{\infty}  k p(k) = \sum_{k=1}^{\infty}  k(1-p)^{k-1} p = p \sum_{k=1}^{\infty}  k(1-p)^{k-1}.
</me>
Taking the derivative of both sides of
<me>
\sum_{k=0}^{\infty} x^k = \frac{1}{1-x},
</me>
we find that
<me>
\sum_{k=1}^{\infty} k x^{k-1} = \frac{1}{(1-x)^2}.
</me>
Therefore
<me>
\E[Y] = p \sum_{k=1}^{\infty}  k(1-p)^{k-1} = \frac{p}{(1-(1-p))^2} = \frac{p}{p^2} = \frac{1}{p}.
</me>
</p>
</solution-->

					</p>
				</li>
				<li>
					<p>
 <em>[Do not solve this one. It is a long calculation.]</em>  It can be shown that
<me>
\var(Y) = \frac{1-p}{p^2}.
</me>
But you do not need to prove this here. (You use the same trick as in problem 1(d) of writing <m>\E[Y^2] = \E[Y(Y-1)] + E[Y]</m>.)


<!--solution>
<p>
We will calculate <m>\E[Y^2] - (\E[Y])^2 = \E[Y(Y-1)] + \E[Y] - (\E[Y])^2</m>.

</p>
<md>
<mrow>
\E[Y(Y-1)]  &amp;=&amp; \sum_{k=1}^{\infty}  k(k-1) (1-p)^{k-1} p
</mrow>
<mrow>
&amp;= p (1-p) \sum_{k=2}^{\infty}  k(k-1) (1-p)^{k-2}.
</mrow>
</md>
<p>
Taking the derivative of both sides of
<me>
\sum_{k=1}^{\infty} kx^{k-1} = \frac{1}{(1-x)^2},
</me>
we find that
<me>
\sum_{k=2}^{\infty} k(k-1) x^{k-2} = \frac{2}{(1-x)^3}.
</me>
Therefore
</p>
<md>
<mrow>
\E[Y(Y-1)]  &amp;=  p (1-p) \sum_{k=2}^{\infty}  k(k-1) (1-p)^{k-2}
</mrow>
<mrow>
&amp;= p (1-p) \frac{2}{(1- (1-p))^3} = \frac{p(1-p)}{p^3}
</mrow>
<mrow>
&amp; = \frac{p(1-p)}{p^2}.
</mrow>
</md>
<p>

</p>
</solution-->

					</p>
				</li>
			</ol>


				</p>
			</statement>
		</exercise>
		<exercise>
			<title>Poisson Random Variable</title>
			<idx><h>Poisson Random Variable</h></idx>
			<statement>
				<p>
The Poisson random variable <m>Z</m> for parameter <m>\lambda &gt; 0</m> has PMF given by
<me>
p(k) = e^{-\lambda} \frac{\lambda^k}{k!}.
</me>



			<ol>


				<li>
					<p>
 Use the fact that
<me>
\sum_{k=0}^{\infty} \frac{x^k}{k!} = e^{x}
</me>
to prove that  <m>p(k)</m> is a PMF.

<!--solution>
<p>
Once again, it is clear that <m>0 \leq p(k) </m> for all <m>k</m>. These numbers sum to
<me>
\sum_{k=0}^{\infty} e^{-\lambda} \frac{\lambda^k}{k!} = e^{-\lambda} \sum_{k=0}^{\infty}  \frac{\lambda^k}{k!}
= e^{-\lambda} e^{\lambda} =1.
</me>
Since all terms are nonnegative and they sum to 1, each term must be less than 1.
</p>
</solution-->

					</p>
				</li>
				<li>
					<p>
 Show that
<me>
\E[Z] = \lambda.
</me>

<!--solution>
<p>
</p>
<md>
<mrow>
\E[Z] &amp;= \sum_{k=0}^{\infty} k e^{-\lambda} \frac{\lambda^k}{k!}
\, = \,  \sum_{k=1}^{\infty} e^{-\lambda} \frac{\lambda^k}{(k-1)!}
</mrow>
<mrow>
&amp; =  \lambda \sum_{k=1}^{\infty} e^{-\lambda} \frac{\lambda^{k-1}}{(k-1)!}
\,= \,  \lambda \sum_{j=0}^{\infty} e^{-\lambda} \frac{\lambda^{j}}{j!}
</mrow>
<mrow>
&amp; = \lambda.
</mrow>
</md>
<p>
</p>
</solution-->

					</p>
				</li>
				<li>
					<p>
 <em>[Don't solve this one. The calculation isn't as bad as the other variance calculations above. But it is still a bit long.]</em> It can be shown that
<me>
\var[Z] = \lambda
</me>
as well! Again, we need to use the trick
<me>
\E[Z^2] = \E[Z(Z-1)] + \E[Z].
</me>
This time, we also need to be comfortable with reindexing infinite series.

<!--solution>
<p>
Here is the hard work:
</p>
<md>
<mrow>
\E[Z(Z-1)] &amp;= \sum_{k=0}^{\infty} k(k-1) e^{-\lambda} \frac{\lambda^k}{k!}
</mrow>
<mrow>
&amp;= \lambda^2 e^{-\lambda} \sum_{k=2}^{\infty}   \frac{\lambda^{k-2}}{(k-2)!}
</mrow>
<mrow>
&amp;= \lambda^2 e^{-\lambda} \sum_{j=0}^{\infty}   \frac{\lambda^{j}}{j!}
</mrow>
<mrow>
&amp;= \lambda^2 e^{-\lambda}e^{\lambda} = \lambda^2.
</mrow>
</md>
<p>
That wasn't so bad! Our variance calculation is
</p>
<md>
<mrow>
\var(Z) &amp;= \E[Z^2] - (\E[Z])^2 = \E[Z(Z-1)] + \E[Z]- (\E[Z])^2
</mrow>
<mrow>
&amp;= \lambda^2 + \lambda - \lambda^2 \, =\,  \lambda.
</mrow>
</md>
<p>
Fun fact: the expected value is also called the "first moment."
The variance is also called the "second moment." Can you guess what the third moment of the Poisson distribution is? That's right: it's also equal to <m>\lambda</m>. How about the fourth moment? Yep, <m>\lambda</m> again.

			</p><p>
In fact, every moment of the Poisson distribution is equal to <m>\lambda</m>. (This is analogous to how all of the derivatives of <m>e^x</m> are also <m>e^x</m>.) Each of the moments tell you something about the shape of the distribution. So in a poetic sense, the Poisson distribution must be the nicest-shaped bell curve centered at <m>x=\lambda</m>.

</p>
</solution-->


					</p>
				</li>
				<li>
					<p>
 In this part, you will show that when <m>n</m> is very large and <m>p</m> is very small, the Poisson PMF for
<me>
\lambda :=np
</me>
is a good approximation (for small <m>k</m>) of  the binomial PMF with parameters <m>n</m> and <m>p</m>.
We will fix <m>k \in \Z_{\geq 0}</m> to be  constant and let <m>n \rightarrow \infty</m>.
You will show that
<me>
{n \choose k} p^k (1-p)^{n-k} \approx e^{-\lambda} \frac{\lambda^k}{k!}   \mbox{if } k \ll n.
</me>
Use the following facts which hold for <m>n \rightarrow \infty</m> and any constants <m>c,d \in \Z_{\geq 0}</m>.
</p>
<md>
<mrow>
\lim_{n \rightarrow \infty} \frac{n -c}{n} &amp;= 1,
&amp;
\lim_{n \rightarrow \infty} \left( 1 - \frac{c}{n} \right)^{-d} &amp;= 1,
&amp;
\lim_{n \rightarrow \infty} \left( 1 - \frac{c}{n} \right)^n &amp;= e^{-c}.
</mrow>
</md>
<p>


<!--solution>
<p>
Keep in mind that <em><m>k</m> is a fixed number</em> while the size <m>n</m> of the network increases to infinity. This lets us use the three limits listed above.
</p>
<md>
<mrow>
{n \choose k} p^k (1-p)^{n-k}
&amp;= \frac{n!}{k! (n-k)!} \left( \frac{\lambda} {n}\right)^k  \left( 1 -  \frac{\lambda}{n} \right)^{n-k}
</mrow>
<mrow>
&amp;= \frac{\lambda^k} {k!} \left( \frac{n}{n} \frac{n-1}{n} \cdots \frac{n-k+1}{n} \right) \left( 1 -  \frac{\lambda}{n} \right)^{n} \left( 1 -  \frac{\lambda}{n} \right)^{-k}
</mrow>
<mrow>
&amp; \rightarrow
\frac{\lambda^k} {k!}  \cdot \big( 1 \cdot 1 \cdots 1  \big) \cdot  e^{-\lambda} \cdot 1 = e^{-\lambda} \frac{\lambda^k}{k!}
</mrow>
</md>
<p>
What this is saying is that as <m>n \rightarrow \infty</m>, the binomial distribution for <m>n</m> and <m>p</m> looks more and more like the Poisson distribution for <m>\lambda=np</m>.
</p>
</solution-->

					</p>
				</li>
			</ol>

				</p>
			</statement>
		</exercise>
	</exercises>


</chapter>
