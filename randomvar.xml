<?xml version="1.0" encoding="UTF-8" ?>





<chapter xml:id="randvar" xmlns:xi="http://www.w3.org/2001/XInclude">
	<title>Discrete Random Variables</title>
	<introduction>
		<p>

			</p><p>



</p>
</introduction>
<section xml:id="randvar0">
<title>Discrete Random Variables</title>
<p>

In an experiment <m>X</m>, we pick an element from our finite <em>sample space</em> <m>\Omega</m> and then make note of one of its numerical properties. For example, we could take <m>\Omega</m> to be the set of vertices in our graph, and let <m>X</m> be the degree of the chosen vertex.


			</p><p>


A <em>discrete random variable</em> <m>X: \Omega \rightarrow \R</m> is a real-valued function on the outcome of an experiment that can take finite or a countably infinite number of values. In other words, the image <m> T \subset \R</m> is a finite or countably infinite set. Most typically, our discrete random variables will only take on nonnegative integer values, so  <m>T = \Z_{\geq 0}</m> or <m>T = \{ 0, 1, 2, \ldots, M \}</m>.



			</p><p>
So at the end of it all, <m>X</m> is just a <em>function</em> from a set <m>\Omega</m> to <m>\R</m>. So what's with all the strange notation?
Let's start with the sample space <m>\Omega</m>. This is just a set. Why not call it <m>S</m>? We use <m>\Omega</m> as  a mnemonic for "outcome." Since we are running an experiment (multiple times), each trial produces an <em>outcome</em>. We then take a measurement of that outcome (represented by the random variable <m>X</m>).

			</p><p>

Now, the random variable <m>X</m> is actually a real-valued function <m>X: \Omega \rightarrow \R</m>.  So why use
<m>X</m> instead of <m>f</m>? Well, we are taking a measurement of an outcome of an experiment. In this context, we are more interested in the value of the measurement. The symbol  <m>X</m> encourages us to pay attention to the measurement (not the function) because it reminds us of the variable <m>x</m> from algebra.


</p>
<subsection xml:id="randvar1">
<title>Probability Mass Function</title>
<p>

A discrete random variable <m>X</m> has an associated <em>probability mass function (PMF)</em>
<me>
p_X(t) = \P [ X = t]
</me>
which gives the probability of each numerical value that the random variable can take. When <m>X</m> is clear from the context, we simply write <m>p(t) = \P [X=t]</m>.


		<example>
			<title>PMF for a Random Vertex Degree</title>
			<statement>
				<p>
Consider the experiment where we take <m>X</m> to be the degree of a vertex from the network shown below, chosen uniformly at random (meaning that every vertex is equally likely). Find the PMF for this experiment.




			<image width="60%" xml:id="fig-img-randvar0" source="images/graph7.png" />




<!--solution>
<p>
Here are the probabilities of picking a vertex of degree <m>0 \leq t \leq 6</m>:
<me>
\begin{array}{c|c|c|c|c|c|c}
\P(0) &amp; \P(1) &amp; \P(2) &amp; \P(3) &amp; \P(4) &amp; \P(5) &amp; \P(6) \\
\hline
\rule{0pt}{3.5ex} 0 &amp; 0 &amp;\frac{1}{7} &amp;\frac{4}{7}&amp;\frac{2}{7}&amp;0&amp; 0\\
\end{array}
</me>
For example, there are two vertices with degree four: vertex 6 and vertex 7.
</p>
</solution-->

				</p>
			</statement>
		</example>


</p>
</subsection>
<subsection xml:id="randvar2">
<title>Properties of a PMF</title>
<p>

The PMF of a random variable has the following properties.
		<ul>
			<li>
			<p>
  We always have
<me>
\sum_{t \in T} \P[ X = t] = 1.
</me>
			</p>
			</li>
			<li>
			<p>
 When <m>\Omega</m> is a finite set, we can find <m>\P[X = t]</m> by calculating
<me>
p(t) = \P[X=t] = \frac{ | \{ \omega \in \Omega | X(\omega) = t \} |} { | \Omega |}.
</me>
			</p>
			</li>
			<li>
			<p>
 A function <m>f: T \rightarrow \R</m> is a PMF if and only if
		<ul>
			<li>
			<p>
  <m>f(t) \geq 0</m> for all <m>t \in T</m>, and
			</p>
			</li>
			<li>
			<p>
  <m>\sum_{t \in T} f(t) = 1</m>.
			</p>
			</li>
		</ul>
			</p>
			</li>
		</ul>



</p>
</subsection>
</section>
<section xml:id="randvar3">
<title>Events</title>
<p>

A subset <m>A \subset \Omega</m> of the sample space is called an <em>event</em>. The <em>probability of event <m>A</m></em> is
<me>
\P(A) = \sum_{a \in A} p_X(a).
</me>
The subset <m>A</m> is called an "event" because we often give a description of the elements in <m>A</m> using some shared property, rather than directly listing the elements.


		<example>
			<title>Probability of Events</title>
			<statement>
				<p>
Suppose that we pick a random vertex from our example network.

			<image width="60%" xml:id="fig-img-randvar1" source="images/graph7.png" />


Let <m>A</m> be the event that the degree of the vertex is even. Let <m>B</m> be the event that the degree of the vertex is at least 3.
		<ul>
			<li>
			<p>
 List the elements of <m>A</m>, <m>B</m>, <m>A \cap B</m> and <m>A \cup B</m>.
			</p>
			</li>
			<li>
			<p>
 Next, calculate <m>\P[A]</m>, <m>\P[B]</m>, <m>\P[A \cap B]</m>  and <m>\P[A \cup B]</m>.
			</p>
			</li>
		</ul>

<!--solution>
<p>
<me>
A = \{ 1, 6, 7\} \qquad B = \{ 2, 3, 4, 5, 6, 7 \}
</me>

<me>
A\cap B = \{ 6, 7\} \qquad A \cup B = \{ 1,2,3,4,5,6,7\}
</me>

<me>
\P[A] = \frac{3}{7} \qquad \P[B] = \frac{6}{7} \qquad \P[A \cap B] = \frac{2}{7} \qquad \P[A \cup B] = 1
</me>
</p>
</solution-->

				</p>
			</statement>
		</example>


		<example>
			<title>Union of Events</title>
			<statement>
				<p>
For any sample space <m>\Omega</m> and  any events <m>A</m> and <m>B</m>, explain why
<me>
\P[A \cup B] = \P[A] + \P[B] - \P[A \cap B].
</me>


<!--solution>
<p>
This follows from the inclusion-exclusion formula
<me>
|A \cup B| = |A| +  |B| - |A \cap B|.
</me>
</p>
</solution-->

				</p>
			</statement>
		</example>




</p>
<subsection xml:id="randvar4">
<title>Conditional Probability</title>
<p>

Given two events <m>A, B \subset \Omega</m>, the <em>conditional probability of <m>A</m> given <m>B</m></em> is
<me>
\P[A \mid B] = \frac{\P[A \cap B]}{\P[B]}.
</me>
This is the probability of event <m>A</m>, given that event <m>B</m> is true.

		<example>
			<title>Conditional Probabillity</title>
			<statement>
				<p>
Pick a random vertex from our example network. Let's use the same events from the first example in this subsection:
		<ul>
			<li>
			<p>
 Let <m>A</m> be the event that the degree of the vertex is even.
			</p>
			</li>
			<li>
			<p>
 Let <m>B</m> be the event that the degree of the vertex is at least 3.
			</p>
			</li>
		</ul>
Calculate <m>\P[A \mid B]</m> and <m>\P[B \mid A]</m>.

			<image width="60%" xml:id="fig-img-randvar2" source="images/graph7.png" />

<!--solution>
<p>
<me>
\P[A \mid B] = \frac{2}{6} = \frac{1}{3} \qquad \mbox{and}  \qquad \P[B \mid A] = \frac{2}{3}
</me>
</p>
</solution-->


				</p>
			</statement>
		</example>

</p>
</subsection>
<subsection xml:id="randvar5">
<title>Independent Events and Dependent Events</title>
<p>

Two events <m>A,B \in \Omega</m> are <em>independent</em> when
<me>
\P[A \cap B] = \P[A] \P[B].
</me>
Otherwise, these events are dependent.


		<example>
			<title>Probability of Independent Events</title>
			<statement>
				<p>
Show that when <m>A</m> and <m>B</m> are independent, we have
<me>
\P[A \mid B ] = \P[A].
</me>
In other words, assuming that event <m>B</m> holds has no effect on the probability that event <m>A</m> holds.


<!--solution>
<p>
<me>
\P[A \mid B] = \frac{\P[A \cap B]}{\P[B]} = \frac{\P[A] \, \P[B]}{\P[B]} = \P[A].
</me>
</p>
</solution-->

				</p>
			</statement>
		</example>


		<example>
			<title>Example of Independent Events</title>
			<statement>
				<p>
Show that the events <m>A</m> and <m>B</m> from the network example problems above are dependent.

<!--solution>
<p>
We have
<me>
\P[A \cap B] = \frac{2}{7}  \qquad \mbox{ but } \qquad  \P[A] \P[B] = \frac{3}{7} \cdot \frac{6}{7} = \frac{18}{49}.
</me>
Since <m>\P[A \mid B] \neq \P[A]</m>, these are dependent events.
</p>
</solution-->

				</p>
			</statement>
		</example>




</p>
</subsection>
</section>
<section xml:id="randvar6">
<title>CDF and CCDF</title>
<p>

</p>
<subsection xml:id="randvar7">
<title>Cumulative Density Function</title>
<p>


The <em>cumulative distribution function (CDF)</em> <m>F_X: \R \rightarrow [0,1]</m> of a discrete random variable <m>X</m> is given by
<me>
F_X(t) = \P(X \leq t) = \sum_{k \leq t} p_X(k).
</me>
So the CDF <m>F_X(t)</m> captures the probability that the value of <m>X</m> is <em>at most</em> <m>t</m>, while the PMF <m>p_X(t)</m> captures the probability that the value of <m>X</m> is <em>exactly</em> <m>t</m>.

			</p><p>

		<example>
			<title>CDF for a Random Vertex Degree</title>
			<statement>
				<p>
Find the CDF for the random variable <m>X</m>, the degree of a randomly chosen vertex of our example network.

			<image width="60%" xml:id="fig-img-randvar3" source="images/graph7.png" />


<!--solution>
<p>
<me>
\begin{array}{c|c|c|c|c|c|c}
F_X(0) &amp; F_X(1) &amp; F_X(2) &amp; F_X(3) &amp; F_X(4) &amp; F_X(5) &amp; F_X(6) \\
\hline
\rule{0pt}{3.5ex} 0&amp;0&amp;\frac{1}{7}&amp;\frac{5}{7}&amp;1&amp;1&amp;1 \\
\end{array}
</me>
For example, among the 7 vertices, there are 5   vertices with degree at most 3,
</p>
</solution-->

				</p>
			</statement>
		</example>


			</p><p>



The CDF <m>F_X</m> of a discrete random variable satisfies the following properties:
		<ul>
			<li>
			<p>
 <m>F_X</m> is weakly increasing (aka monotonically nondecreasing). That is,
<me>
s \leq t \qquad \Longrightarrow  \qquad F_X(s) \leq F_X(t).
</me>
			</p>
			</li>
			<li>
			<p>
 <m>F_X(t)</m> tends to 0 as <m>t \rightarrow - \infty</m> , and tends to 1 as <m>t \rightarrow \infty</m>.
			</p>
			</li>
			<li>
			<p>
 Since <m>X</m> is a discrete random variable, the CDF <m>F_X(t)</m> is a piecewise constant function of <m>t</m>.
			</p>
			</li>
		</ul>


		<example>
			<title>Connecting the PMF with the CDF</title>
			<statement>
				<p>
Suppose that <m>X</m> takes on discrete integer values. Explain why
for any <m>k \in \Z</m>,
<me>
F_X(k) = \sum_{i=-\infty}^k p_X(i)
</me>
and
<me>
p_X(k) = F_X(k) - F_X(k-1).
</me>
In other words, if you know the PMF, then you can find the CDF, and vice versa.

<!--solution>
<p>
We have
<me>
F_X(k) = \sum_{i=-\infty}^k p_X(i)
</me>
because this is the definition of the CDF.
Therefore, we have
<me>
p_X(k) = F_X(k) - F_X(k-1) = \sum_{i=-\infty}^k p_X(i) - \sum_{i=-\infty}^{k-1} p_X(i) = p_X(k).
</me>
</p>
</solution-->

				</p>
			</statement>
		</example>







</p>
</subsection>
<subsection xml:id="randvar8">
<title>Complementary Cumulative Density Function</title>
<p>


The <em>complementary cumulative distribution function (CCDF)</em> <m>F_X: \R \rightarrow [0,1]</m> of a discrete random variable <m>X</m> is given by
<me>
\overline{F}_X(t) = \P(X &gt; t) = \sum_{k &gt; t} p_X(k) = 1 - F_X(t).
</me>
So the CCDF <m>\overline{F}_X(t)</m> captures the probability that the value of <m>X</m> is <em>greater than</em> <m>t</m>.

			</p><p>

		<example>
			<title>CCDF for Random Vertex Degree</title>
			<statement>
				<p>
Find the CCDF for the random variable <m>X</m> where, as above, the value of <m>X</m> is the degree of a randomly chosen vertex of our example network.

			<image width="60%" xml:id="fig-img-randvar4" source="images/graph7.png" />


<!--solution>
<p>
<me>
\begin{array}{c|c|c|c|c|c|c}
\overline{F}_X(0) &amp; \overline{F}_X(1) &amp; \overline{F}_X(2) &amp; \overline{F}_X(3) &amp; \overline{F}_X(4) &amp; \overline{F}_X(5) &amp; \overline{F}_X(6) \\
\hline
&amp;&amp;&amp;&amp;&amp;&amp; \\
1&amp;1&amp;\frac{6}{7}&amp;\frac{2}{7}&amp;0&amp;0&amp;0 \\
\end{array}
</me>
</p>
</solution-->

				</p>
			</statement>
		</example>



		<example>
			<title>Properties of a CCDF</title>
			<statement>
				<p>
Using the fact that <m>\overline{F}_X(t) = 1 - F_X(t)</m>, write down the properties of a CCDF that are analogous to the CDF properties  listed above.

<!--solution>
<p>
The CCDF <m>\overline{F}_X</m> of a discrete random variable satisfies the following properties:
		<ul>
			<li>
			<p>
 <m>\overline{F}_X</m> is weakly decreasing (aka monotonically nonincreasing). That is,
<me>
s \leq t \qquad \Longrightarrow  \qquad \overline{F}_X(s) \geq \overline{F}_X(t).
</me>
			</p>
			</li>
			<li>
			<p>
 <m>\overline{F}_X(t)</m> tends to 1 as <m>t \rightarrow - \infty</m> , and tends to 0 as <m>t \rightarrow \infty</m>.
			</p>
			</li>
			<li>
			<p>
 Since <m>X</m> is a discrete random variable, the CCDF <m>\overline{F}_X(t)</m> is a piecewise constant function of <m>t</m>.
			</p>
			</li>
		</ul>

</p>
</solution-->

				</p>
			</statement>
		</example>




		<example>
			<title>Connecting the PMF and the CCDF</title>
			<statement>
				<p>
Suppose that <m>X</m> takes on discrete integer values. Develop formulas for going back and forth between the PMF and the CCDF (analogous to how you connected the PMF and CDF above).


<!--solution>
<p>


For any <m>k \in \Z</m>,
<me>
\overline{F}_X(k) = \sum_{i=k+1}^{\infty} p_X(i)
</me>
by the definition of a CCDF. We then have
<me>
\overline{F}_X(k-1) -  \overline{F}_X(k)= \sum_{i=k}^{\infty} p_X(i) - \sum_{i=k+1}^{\infty} p_X(i) =
p_X(k).
</me>
In other words, if you know the PMF, then you can find the CCDF, and vice versa.

</p>
</solution-->

				</p>
			</statement>
		</example>




</p>
</subsection>
<subsection xml:id="randvar9">
<title>Example: The Sum of Two Dice</title>
<p>

Let's run an experiment where <m>X</m> is the outcome when we roll two fair 6-sided dice.

		<example>
			<title>Sum of Two Dice</title>
			<statement>
				<p>
Find the values of PMF <m>p(t) = p_X(t)</m>, CDF <m>F(t) = F_X(t)</m> and CCDF <m>\overline{F}(t) = \overline{F}_X(t)</m>. Use the domain <m>0 \leq t \leq 12</m> for each.

<!--solution>
<p>



<me>
\begin{array}{c|c|c|c|c|c|c|c|c|c|c|c|c}
p(0) &amp; p(1) &amp; p(2) &amp; p(3) &amp; p(4) &amp; p(5) &amp; p(6) &amp;
p(7) &amp; p(8) &amp; p(9) &amp; p(10) &amp; p(11) &amp; p(12)
\\
\hline
&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp; \\
0&amp;0&amp;\frac{1}{36}&amp;\frac{2}{36}&amp;\frac{3}{36}&amp;\frac{4}{36}&amp;\frac{5}{36}&amp;\frac{6}{36}&amp;\frac{5}{36}&amp;\frac{4}{36}&amp;\frac{3}{36}&amp;\frac{2}{36}&amp;\frac{1}{36} \\
\end{array}
</me>


			</p><p>


<me>
\begin{array}{c|c|c|c|c|c|c|c|c|c|c|c|c}
F(0) &amp; F(1) &amp; F(2) &amp; F(3) &amp; F(4) &amp; F(5) &amp; F(6) &amp;
F(7) &amp; F(8) &amp; F(9) &amp; F(10) &amp; F(11) &amp; F(12)
\\
\hline
&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp; \\
0&amp;0&amp;\frac{1}{36}&amp;\frac{3}{36}&amp;\frac{6}{36}&amp;\frac{10}{36}&amp;\frac{15}{36}&amp;\frac{21}{36}&amp;\frac{26}{36}&amp;\frac{30}{36}&amp;\frac{33}{36}&amp;\frac{35}{36}&amp;1 \\
\end{array}
</me>



			</p><p>


<me>
\begin{array}{c|c|c|c|c|c|c|c|c|c|c|c|c}
\overline{F}(0) &amp; \overline{F}(1) &amp; \overline{F}(2) &amp; \overline{F}(3) &amp; \overline{F}(4) &amp; \overline{F}(5) &amp; \overline{F}(6) &amp;
\overline{F}(7) &amp; \overline{F}(8) &amp; \overline{F}(9) &amp; \overline{F}(10) &amp; \overline{F}(11) &amp; \overline{F}(12)
\\
\hline
&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp; \\
1&amp; 1&amp;\frac{35}{36}&amp;\frac{33}{36}&amp;\frac{30}{36}&amp;\frac{26}{36}&amp;\frac{21}{36}&amp;\frac{15}{36}&amp;\frac{10}{36}&amp;\frac{6}{36}&amp;\frac{3}{36}&amp;\frac{1}{36}&amp;0 \\
\end{array}
</me>



</p>
</solution-->




				</p>
			</statement>
		</example>

		<example>
			<title>Sketching PMF, CDF, CCDF for Two Dice</title>
			<statement>
				<p>
Sketch the graphs of the PMF, CDF and CCDF. Make any observations that you can about how these graphs are related.



		<ul>
			<li>
			<p>
 PMF  <m>\qquad p(t)</m>

			<image width="50%" xml:id="fig-img-randvar5">
				<latex-image>
\begin{tikzpicture}[scale=.5, axis line style/.style={thick, -stealth}]

\begin{scope}

\draw [axis line style] (0,0) z-z-z (12.5,0);
\draw [axis line style] (0,0) z-z-z (0,7.5);



\foreach \x in {1,...,12} {
\draw[gray] (\x,0) z-z-z (\x,7);
\draw (<m>(\x,0) + (0,-2pt)</m>) z-z-z (<m>(\x,0) + (0,2pt)</m>)
node [below] {<m>\x</m>};

}

\foreach \y in {.25, .5, .75, 1} {
\draw[gray] (0,\y*7) z-z-z (12,\y*7);
\draw (<m>(0,\y*7) + (-2pt,0)</m>) z-z-z (<m>(0,\y*7) + (2pt,0)</m>)
node [left] {<m>\y</m>};
}

\end{scope}

\end{tikzpicture}
				</latex-image>
			</image>




			</p>
			</li>
			<li>
			<p>
 CDF  <m>\qquad F(t) = \P(X \leq t) = \sum_{k \leq t} p(k).</m>


			<image width="50%" xml:id="fig-img-randvar6">
				<latex-image>
\begin{tikzpicture}[scale=.5, axis line style/.style={thick, -stealth}]

\begin{scope}

\draw [axis line style] (0,0) z-z-z (12.5,0);
\draw [axis line style] (0,0) z-z-z (0,7.5);



\foreach \x in {1,...,12} {
\draw[gray] (\x,0) z-z-z (\x,7);
\draw (<m>(\x,0) + (0,-2pt)</m>) z-z-z (<m>(\x,0) + (0,2pt)</m>)
node [below] {<m>\x</m>};

}

\foreach \y in {.25, .5, .75, 1} {
\draw[gray] (0,\y*7) z-z-z (12,\y*7);
\draw (<m>(0,\y*7) + (-2pt,0)</m>) z-z-z (<m>(0,\y*7) + (2pt,0)</m>)
node [left] {<m>\y</m>};
}

\end{scope}

\end{tikzpicture}
				</latex-image>
			</image>




			</p>
			</li>
			<li>
			<p>
 CCDF  <m>\qquad  \overline{F}(t) = \P(X &gt; t) = \sum_{k &gt; t} p(k) = 1 - F(t)</m>

			<image width="50%" xml:id="fig-img-randvar7">
				<latex-image>
\begin{tikzpicture}[scale=.5, axis line style/.style={thick, -stealth}]

\begin{scope}

\draw [axis line style] (0,0) z-z-z (12.5,0);
\draw [axis line style] (0,0) z-z-z (0,7.5);



\foreach \x in {1,...,12} {
\draw[gray] (\x,0) z-z-z (\x,7);
\draw (<m>(\x,0) + (0,-2pt)</m>) z-z-z (<m>(\x,0) + (0,2pt)</m>)
node [below] {<m>\x</m>};

}

\foreach \y in {.25, .5, .75, 1} {
\draw[gray] (0,\y*7) z-z-z (12,\y*7);
\draw (<m>(0,\y*7) + (-2pt,0)</m>) z-z-z (<m>(0,\y*7) + (2pt,0)</m>)
node [left] {<m>\y</m>};
}

\end{scope}

\end{tikzpicture}
				</latex-image>
			</image>


			</p>
			</li>
		</ul>




<!--solution>
<p>

The following graphs are drawn to the same scale. The <m>x</m>-axis  spans <m>[0,12]</m> and the <m>y</m>-axis spans <m>[0,1]</m>.

			<image width="70%" xml:id="fig-img-randvar8">
				<latex-image>
\begin{tikzpicture}[scale=.5,axis line style/.style={thick, -stealth}] %mathbook width=70%


\begin{scope}

\draw [axis line style] (0,0) z-z-z (12.5,0);
\draw [axis line style] (0,0) z-z-z (0,7.5);


\node at (15,3.5) {PMF};

\foreach \x in {1,...,12} {
\draw[gray] (\x,0) z-z-z (\x,7);
\draw (<m>(\x,0) + (0,-2pt)</m>) z-z-z (<m>(\x,0) + (0,2pt)</m>)
node [below] {<m>\x</m>};

}

\foreach \y in {.25, .5, .75, 1} {
\draw[gray] (0,\y*7) z-z-z (12,\y*7);
\draw (<m>(0,\y*7) + (-2pt,0)</m>) z-z-z (<m>(0,\y*7) + (2pt,0)</m>)
node [left] {<m>\y</m>};
}

\draw[very thick, blue]
(0,0) z-z-z (1,0) z-z-z (2,7*1/36) z-z-z ( 3,7*2/36) z-z-z (4 ,7*3/36) z-z-z ( 5,7*4/36) z-z-z (6 ,7*5/36) z-z-z (7 ,7*6/36) z-z-z ( 8,7*5/36) z-z-z (9 ,7*4/36) z-z-z (10 ,7*3/36) z-z-z (11 ,7*2/36) z-z-z (12 ,7*1/36);

\end{scope}



\begin{scope}[shift={(0,-10)}]

\draw [axis line style] (0,0) z-z-z (12.5,0);
\draw [axis line style] (0,0) z-z-z (0,7.5);


\node at (15,3.5) {CDF};


\foreach \x in {1,...,12} {
\draw[gray] (\x,0) z-z-z (\x,7);
\draw (<m>(\x,0) + (0,-2pt)</m>) z-z-z (<m>(\x,0) + (0,2pt)</m>)
node [below] {<m>\x</m>};

}

\foreach \y in {.25, .5, .75, 1} {
\draw[gray] (0,\y*7) z-z-z (12,\y*7);
\draw (<m>(0,\y*7) + (-2pt,0)</m>) z-z-z (<m>(0,\y*7) + (2pt,0)</m>)
node [left] {<m>\y</m>};
}

\draw[very thick, blue]
(0,0) z-z-z (1,0) z-z-z (2,7*1/36) z-z-z ( 3,7*3/36) z-z-z (4 ,7*6/36) z-z-z ( 5,7*10/36) z-z-z (6 ,7*15/36) z-z-z (7 ,7*21/36) z-z-z ( 8,7*26/36) z-z-z (9 ,7*30/36) z-z-z (10 ,7*33/36) z-z-z (11 ,7*35/36) z-z-z (12 ,7*36/36);


\end{scope}

\begin{scope}[shift={(0,-20)}]

\draw [axis line style] (0,0) z-z-z (12.5,0);
\draw [axis line style] (0,0) z-z-z (0,7.5);


\node at (15,3.5) {CCDF };


\foreach \x in {1,...,12} {
\draw[gray] (\x,0) z-z-z (\x,7);
\draw (<m>(\x,0) + (0,-2pt)</m>) z-z-z (<m>(\x,0) + (0,2pt)</m>)
node [below] {<m>\x</m>};

}

\foreach \y in {.25, .5, .75, 1} {
\draw[gray] (0,\y*7) z-z-z (12,\y*7);
\draw (<m>(0,\y*7) + (-2pt,0)</m>) z-z-z (<m>(0,\y*7) + (2pt,0)</m>)
node [left] {<m>\y</m>};
}

\draw[very thick, blue]
(0,7*1) z-z-z (1,7*1) z-z-z (2,7*35/36) z-z-z ( 3,7*33/36) z-z-z (4 ,7*30/36) z-z-z ( 5,7*26/36) z-z-z (6 ,7*21/36) z-z-z (7 ,7*15/36) z-z-z ( 8,7*10/36) z-z-z (9 ,7*6/36) z-z-z (10 ,7*3/36) z-z-z (11 ,7*1/36) z-z-z (12 ,7*0/36);

\end{scope}

\end{tikzpicture}
				</latex-image>
			</image>



</p>
</solution-->



				</p>
			</statement>
		</example>

</p>
</subsection>
</section>
<section xml:id="randvar10">
<title>Expectation, Variance and Moments</title>
<p>

</p>
<subsection xml:id="randvar11">
<title>Expected Value</title>
<p>

The <em>expected value</em> of a discrete random variable is
The <em>expected value</em> of a discrete random variable is
<me>
\E[X] = \sum_{\omega \in \Omega} X(\omega) p(\omega)
</me>
which is equivalent to
<me>
\E[X] = \sum_{t \in T} t \cdot p(t) = \sum_{t \in T}  t \cdot \P[X=t].
</me>


		<example>
			<title>Expected Value for Vertex Degree</title>
			<statement>
				<p>
Find <m>\E[X]</m> when <m>X</m> is the degree  a randomly chosen vertex of our example network.

			<image width="60%" xml:id="fig-img-randvar9" source="images/graph7.png" />


<!--solution>
<p>
<me>
\E[X] = 2 \cdot \frac{1}{7} + 3 \cdot \frac{4}{7} + 4 \cdot \frac{2}{7} = \frac{22}{7}
</me>
</p>
</solution-->


				</p>
			</statement>
		</example>

		<example>
			<title>Expected Value for Dice Roll</title>
			<statement>
				<p>
Find <m>\E[X]</m> when <m>X</m> is the outcome when you roll two fair dice.


<!--solution>
<p>
Let's use linearity of expectation (from the next exercise). Let <m>Y</m> be the outcome when we roll one fair die. We have
<me>
\E[Y] = \frac{1}{6} \left( 1 + 2 + 3 + 4 + 5 + 6 \right) = \frac{21}{6} = \frac{7}{2}.
</me>
When we roll two dice, we have
<me>
\E[X] =  \E[Y_1] + \E[Y_2] = \frac{7}{2} + \frac{7}{2} = 7.
</me>
where both <m>Y_1</m> and <m>Y_2</m> are the outcome of rolling one fair die.
</p>
</solution-->

				</p>
			</statement>
		</example>


</p>
</subsection>
<subsection xml:id="randvar12">
<title>Linearity of Expectation</title>
<p>

		<example>
			<title>Linearity of Expectation</title>
			<statement>
				<p>
Prove that if <m>X</m> and <m>Y</m> are two random variables and <m>a, b \in \R</m>, then we have the following <em>linearity of expectation</em> formula:
<me>
\E[a X + b Y] = a \E[X] + b \E[Y].
</me>

<!--solution>
<p>
We have
</p>
<md>
<mrow>
\E[aX+bY] &amp;= \sum_{\omega  \in \Omega} (aX(\omega) + bY(\omega) ) p(\omega)
</mrow>
<mrow>
&amp;= a \sum_{\omega  \in \Omega} X(\omega)p(\omega)  + b \sum_{\omega  \in \Omega} Y(\omega)p(\omega)
</mrow>
<mrow>
&amp;=a \E[X] + b \E[Y].
</mrow>
</md>
<p>
</p>
</solution-->

				</p>
			</statement>
		</example>




</p>
</subsection>
<subsection xml:id="randvar13">
<title>Variance</title>
<p>

The <em>variance</em> <m>\var(X)</m> is given by
<me>
\var(X) = \E \left[ (X - \E[X])^2 \right] = \sum_{t \in T} \left( t - \E[X] \right)^2 p(t).
</me>
The variance is  a measure of dispersion of <m>X</m> around its expected value. It is always nonnegative.

		<example>
			<title>Formula for Variance</title>
			<statement>
				<p>
Show that
<me>
\var(X) = \E[X^2] - (\E[X])^2.
</me>


<!--solution>
<p>

Here  is the argument. The notation is a little dense, so read it slowly. Each step has a simple explanation. For example,
<me>
\E[\E[X]] = \E[X]
</me>
because <m>\E[X]</m> is just a constant. (For the same reason, <m>\E[13] = 13</m> because the value doesn't change as we consider elements of the state space.)
</p>
<md>
<mrow>
\var(X) &amp;=  \E \left[ (X - \E[X])^2 \right]
\, = \, \E[ X^2 -2 X \, \E[X] + \E[X]^2]
</mrow>
<mrow>
&amp;=   \E[ X^2] -\E[2 X \, \E[X]] + \E[\E[X]^2] \, = \, \E[ X^2] -2 \E[X] \, \E[X ] + (\E[X])^2
</mrow>
<mrow>
&amp;=  \E[X^2] - (\E[X])^2
</mrow>
</md>
<p>
where we have used linearity of expectation.

</p>
</solution-->

				</p>
			</statement>
		</example>



		<example>
			<title>Variance for a Random Vertex Degree</title>
			<statement>
				<p>
Calculate the variance of our running example where <m>X</m> is the degree of a randomly chosen vertex from this network.

			<image width="60%" xml:id="fig-img-randvar10" source="images/graph7.png" />



<!--solution>
<p>


<me>
\E[X] = \frac{22}{7}
</me>
and
<me>
\E[X^2] = 2^2 \cdot \frac{1}{7} + 3^2 \cdot \frac{4}{7} + 4^2 \cdot \frac{2}{7}
= \frac{4+36+32}{7} = \frac{72}{7}
</me>
and therefore
<me>
\var(X) = \E[X^2] - \E[X]^2 =  \frac{72}{7} - \left( \frac{22}{7} \right)^2 = \frac{20}{49}.
</me>

</p>
</solution-->

				</p>
			</statement>
		</example>


</p>
</subsection>
<subsection xml:id="randvar14">
<title>Standard Deviation</title>
<p>


The <em>standard deviation</em>
<me>
\sigma = \sqrt{ \var(X) }
</me>
has the same units as the random variable <m>X</m>, so it is easier to interpret than <m>\var(X)</m>. It can be shown that <m>75</m> percent of the sample space satisfies
<me>
\mu - 2 \sigma  \leq X \leq \mu + 2\sigma.
</me>
This is why the standard deviation is a measure of the concentration around the expected value.

</p>
</subsection>
<subsection xml:id="randvar15">
<title>The <m>k</m>th Moment</title>
<p>

The <em><m>k</m>th moment</em> of the random variable <m>X</m> is <m></m>\E[X^k],<m></m>
the expected value of <m>X^k</m>. The <em><m>k</m>th central moment</em> is
<me>
\E \left[ ( X - \E[X])^k \right].
</me>
So the second central moment is the variance, <m>\var(X)</m>. The third central moment is the <em>skewness</em>, which measures the asymmetry of the PMF. The fourth central moment its the <em>kurtosis</em>, which measures the "peakness" of the PMF (tall and skinny versus short and squat). We will mostly be interested in variance and the second moment.








</p>
</subsection>
</section>
<section xml:id="randvar16">
<title>Famous Discrete Distributions</title>
<p>

Here are three discrete random variables that will be useful when we talk about random models for complex networks. You will prove the formulas and explore their properties in the exercises.



</p>
<subsection xml:id="randvar17">
<title>Binomial Distribution</title>
<p>


Flip a weighted coin <m>n</m> times, where <m>p</m> is the probability of obtaining heads, and <m>1-p</m> is the probability of obtaining tails. Define <m>X</m> to be the number of heads in the <m>n</m> tosses. This is the <em>binomial random variable with parameters <m>n</m> and <m>p</m></em>.


The PMF is
<me>
p(k) = {n \choose k} p^k (1 - p)^{n-k}.
</me>
The  expectation is
<me>
E[X] = np.
</me>
The variance is
<me>
\var(X) = np(1-p).
</me>
Here are the PMF and CDF of a binomial random variable.

</p>
<table>
<tabular top="minor" left="minor" bottom="minor" right="minor">
<row>
<cell>
			<image width="45%" xml:id="fig-img-randvar11" source="images/Binomial_pmf.png" />
</cell>
<cell>

</cell>
<cell>
			<image width="45%" xml:id="fig-img-randvar12" source="images/Binomial_cdf.png" />
</cell>
</row>
<row>
<cell>
PMF
</cell>
<cell>

</cell>
<cell>
CDF
</cell>
</row>
</tabular>
</table>
<p>


</p>
</subsection>
<subsection xml:id="randvar18">
<title>Geometric Distribution</title>
<p>


Once again, we have a weighted coin where <m>p</m> is the probability of obtaining heads, and <m>1-p</m> is the probability of obtaining tails. Instead of flipping our coin for a fixed number of times, we will flip it until we first encounter a heads. This experiment gives the geometric random variable <m>Y</m>. . This is the <em>geometric random variable for <m>p</m></em>.




The PMF is
<me>
p(k) =  (1 - p)^{k-1}  p.
</me>
The  expectation is
<me>
E[Y] = \frac{1}{p}.
</me>
The variance is
<me>
\var(Y) = \frac{1-p}{p^2}
</me>
Here are the PMF and CDF of a geometric random variable

</p>
<table>
<tabular top="minor" left="minor" bottom="minor" right="minor">
<row>
<cell>
			<image width="45%" xml:id="fig-img-randvar13" source="images/Geo_pmf.png" />
</cell>
<cell>

</cell>
<cell>
			<image width="45%" xml:id="fig-img-randvar14" source="images/Geo_cdf.png" />
</cell>
</row>
<row>
<cell>
PMF
</cell>
<cell>

</cell>
<cell>
CDF
</cell>
</row>
</tabular>
</table>
<p>


</p>
</subsection>
<subsection xml:id="randvar19">
<title>Poisson Distribution</title>
<p>


The Poisson random variable <m>Z</m> for parameter <m>\lambda &gt; 0</m> has PMF given by
<me>
p(k) = e^{-\lambda} \frac{\lambda^k}{k!}.
</me>
The  expectation is
<me>
E[Z] =  \lambda
</me>
The variance is
<me>
\var(Z) =  \lambda
</me>
Here are the PMF and CDF of a poisson random variable.

</p>
<table>
<tabular top="minor" left="minor" bottom="minor" right="minor">
<row>
<cell>
			<image width="45%" xml:id="fig-img-randvar15" source="images/Poisson_pmf.png" />
</cell>
<cell>

</cell>
<cell>
			<image width="45%" xml:id="fig-img-randvar16" source="images/Poisson_cdf.png" />
</cell>
</row>
<row>
<cell>
PMF
</cell>
<cell>

</cell>
<cell>
CDF
</cell>
<cell>

</cell>
</row>
</tabular>
</table>
<p>







</p>
</subsection>
</section>







</chapter>
